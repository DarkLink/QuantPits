#!/usr/bin/env python
"""
Brute Force Fast - å‘é‡åŒ–å¿«é€Ÿæš´åŠ›ç©·ä¸¾ç»„åˆå›æµ‹ + ç»“æœåˆ†æ

ä½¿ç”¨ NumPy/CuPy çŸ©é˜µè¿ç®—æ›¿ä»£ qlib å®˜æ–¹ backtestï¼Œé€Ÿåº¦æå‡çº¦ 5000 å€ã€‚
ç²¾åº¦æœ‰æ‰€é™ä½ï¼ˆå¿½ç•¥æ¶¨è·Œåœã€ç®€åŒ–äº¤æ˜“è´¹ç”¨ï¼‰ï¼Œä½†ç»„åˆæ’åºé«˜åº¦ä¸€è‡´ï¼Œ
é€‚åˆåšç²—ç­›ï¼Œé€‰å‡º Top å€™é€‰åç”¨åŸç‰ˆç²¾ç¡®éªŒè¯ã€‚

è¿è¡Œæ–¹å¼ï¼š
  cd QuantPits && python engine/scripts/brute_force_fast.py

å¸¸ç”¨å‘½ä»¤ï¼š
  # å¿«é€Ÿæµ‹è¯•ï¼ˆæœ€å¤š 3 ä¸ªæ¨¡å‹çš„ç»„åˆï¼‰
  python engine/scripts/brute_force_fast.py --max-combo-size 3

  # ä»…åˆ†æå·²æœ‰ç»“æœï¼ˆä¸é‡æ–°è·‘å›æµ‹ï¼‰
  python engine/scripts/brute_force_fast.py --analysis-only

  # å®Œæ•´ç©·ä¸¾ + åˆ†æ
  python engine/scripts/brute_force_fast.py

  # ä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­
  python engine/scripts/brute_force_fast.py --resume

  # åªè·‘å›æµ‹ã€è·³è¿‡åˆ†æ
  python engine/scripts/brute_force_fast.py --skip-analysis

  # ä½¿ç”¨ GPU åŠ é€Ÿ
  python engine/scripts/brute_force_fast.py --use-gpu

  # è‡ªå®šä¹‰äº¤æ˜“è´¹ç”¨ï¼ˆåŒè¾¹ 0.3%ï¼‰
  python engine/scripts/brute_force_fast.py --cost-rate 0.003
"""

import os
import sys
import json
import gc
import itertools
import logging
import argparse
import time
from datetime import datetime
from collections import Counter
from itertools import chain

import yaml
import pandas as pd
import numpy as np
from tqdm.auto import tqdm

# ---------------------------------------------------------------------------
# è·¯å¾„è®¾ç½®
# ---------------------------------------------------------------------------
import env

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = env.ROOT_DIR
os.chdir(ROOT_DIR)

# ---------------------------------------------------------------------------
# GPU åŠ é€Ÿï¼šè‡ªåŠ¨æ£€æµ‹ CuPy
# ---------------------------------------------------------------------------
_USE_GPU = False
xp = np  # default to numpy


def _init_gpu(force_gpu=False, force_no_gpu=False):
    """åˆå§‹åŒ– GPU æ”¯æŒï¼ˆCuPyï¼‰"""
    global _USE_GPU, xp

    if force_no_gpu:
        _USE_GPU = False
        xp = np
        print("GPU: å·²ç¦ç”¨ (--no-gpu)")
        return

    try:
        import cupy as cp
        # æµ‹è¯• GPU æ˜¯å¦å¯ç”¨
        cp.array([1.0])
        _USE_GPU = True
        xp = cp
        device = cp.cuda.Device()
        print(f"GPU: âœ… å·²å¯ç”¨ CuPy (Device: {device.id}, "
              f"Memory: {device.mem_info[1] / 1024**3:.1f} GB)")
    except Exception as e:
        if force_gpu:
            print(f"GPU: âŒ CuPy ä¸å¯ç”¨: {e}")
            print("è¯·å®‰è£… CuPy: pip install cupy-cuda12x")
            sys.exit(1)
        _USE_GPU = False
        xp = np
        print(f"GPU: æœªå¯ç”¨ (CuPy ä¸å¯ç”¨ï¼Œä½¿ç”¨ NumPy)")


def _to_numpy(arr):
    """å°† CuPy æ•°ç»„è½¬å› NumPy"""
    if _USE_GPU:
        import cupy as cp
        if isinstance(arr, cp.ndarray):
            return cp.asnumpy(arr)
    return np.asarray(arr)


# ---------------------------------------------------------------------------
# å¸¸é‡
# ---------------------------------------------------------------------------
BACKTEST_CONFIG = {
    "account": 100_000_000,
    "exchange_kwargs": {
        "freq": "day",
        "limit_threshold": 0.095,
        "deal_price": "close",
        "open_cost": 0.0005,
        "close_cost": 0.0015,
        "min_cost": 5,
    },
}


# ============================================================================
# Stage 0: åˆå§‹åŒ– & é…ç½®åŠ è½½
# ============================================================================

def init_qlib():
    """åˆå§‹åŒ– Qlib"""
    import qlib
    from qlib.constant import REG_CN
    provider_uri = "~/.qlib/qlib_data/cn_data"
    qlib.init(provider_uri=provider_uri, region=REG_CN)


def load_config(record_file="latest_train_records.json"):
    """åŠ è½½è®­ç»ƒè®°å½•å’Œæ¨¡å‹é…ç½®"""
    with open(record_file, "r") as f:
        train_records = json.load(f)

    with open("config/model_config.json", "r") as f:
        model_config = json.load(f)

    return train_records, model_config


# ============================================================================
# Stage 1: åŠ è½½é¢„æµ‹æ•°æ® + æ”¶ç›Šç‡çŸ©é˜µ
# ============================================================================

def zscore_norm(series):
    """æŒ‰å¤© Z-Score å½’ä¸€åŒ– (å‡å‡å€¼ï¼Œé™¤æ ‡å‡†å·®)"""
    def _norm_func(x):
        std = x.std()
        if std == 0:
            return x - x.mean()
        return (x - x.mean()) / std
    return series.groupby(level="datetime", group_keys=False).apply(_norm_func)


def load_predictions(train_records):
    """
    ä» Qlib Recorder åŠ è½½æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹å€¼ï¼Œå½’ä¸€åŒ–åè¿”å›å®½è¡¨ã€‚

    Returns:
        norm_df: DataFrame, index=(datetime, instrument), columns=model_names
        model_metrics: dict, model_name -> ICIR
    """
    from qlib.workflow import R

    experiment_name = train_records["experiment_name"]
    models = train_records["models"]

    all_preds = []
    model_metrics = {}

    print(f"\n{'='*60}")
    print("Stage 1: åŠ è½½æ¨¡å‹é¢„æµ‹æ•°æ®")
    print(f"{'='*60}")
    print(f"Experiment: {experiment_name}")
    print(f"Models ({len(models)}): {list(models.keys())}")

    for model_name, record_id in models.items():
        try:
            recorder = R.get_recorder(
                recorder_id=record_id, experiment_name=experiment_name
            )

            # åŠ è½½é¢„æµ‹å€¼
            pred = recorder.load_object("pred.pkl")
            if isinstance(pred, pd.Series):
                pred = pred.to_frame("score")
            pred.columns = [model_name]
            all_preds.append(pred)

            # è¯»å– ICIR æŒ‡æ ‡
            raw_metrics = recorder.list_metrics()
            metric_val = 0.0
            for k, v in raw_metrics.items():
                if "ICIR" in k:
                    metric_val = v
                    break
            model_metrics[model_name] = metric_val

            print(f"  [{model_name}] OK. Preds={len(pred)}, ICIR={metric_val:.4f}")
        except Exception as e:
            print(f"  [{model_name}] FAILED: {e}")

    print(f"\næˆåŠŸåŠ è½½ {len(all_preds)}/{len(models)} ä¸ªæ¨¡å‹")

    if not all_preds:
        raise ValueError("æœªåŠ è½½åˆ°ä»»ä½•é¢„æµ‹æ•°æ®ï¼")

    # åˆå¹¶ & Z-Score å½’ä¸€åŒ–
    merged_df = pd.concat(all_preds, axis=1).dropna()
    print(f"åˆå¹¶åæ•°æ®ç»´åº¦: {merged_df.shape}")

    norm_df = pd.DataFrame(index=merged_df.index)
    for col in merged_df.columns:
        norm_df[col] = zscore_norm(merged_df[col])

    return norm_df, model_metrics


def load_returns_matrix(norm_df, freq="week"):
    """
    ä» qlib åŠ è½½ä¸ªè‚¡**æ—¥é¢‘**æ”¶ç›Šç‡ï¼Œå¹¶å¯¹é½åˆ° norm_df çš„ç´¢å¼•ã€‚

    æ— è®º freq æ˜¯ 'week' è¿˜æ˜¯ 'day'ï¼Œéƒ½åŠ è½½æ—¥é¢‘æ”¶ç›Šç‡ã€‚
    å‘¨é¢‘è°ƒä»“é€»è¾‘åœ¨å›æµ‹å¼•æ“ä¸­å¤„ç†ï¼ˆæ¯ rebalance_freq å¤©è°ƒä»“ä¸€æ¬¡ï¼‰ï¼Œ
    è€Œä¸æ˜¯åœ¨æ”¶ç›Šç‡çŸ©é˜µä¸­ç”¨å‰ç» 5 å¤©æ”¶ç›Šç‡æ¥æ¨¡æ‹Ÿã€‚

    è¿”å›:
        returns_wide: DataFrame, index=datetime, columns=instrument (æ—¥é¢‘æ”¶ç›Šç‡)
        benchmark_returns: Series, index=datetime (æ—¥é¢‘åŸºå‡†æ”¶ç›Šç‡)
        dates: DatetimeIndex
        instruments: list
    """
    from qlib.data import D

    print(f"\n--- åŠ è½½æ”¶ç›Šç‡æ•°æ® (äº¤æ˜“é¢‘ç‡={freq}, æ”¶ç›Šç‡=æ—¥é¢‘) ---")

    # è·å–å”¯ä¸€æ—¥æœŸå’Œè‚¡ç¥¨åˆ—è¡¨
    dates = norm_df.index.get_level_values("datetime").unique().sort_values()
    instruments = norm_df.index.get_level_values("instrument").unique().tolist()

    start_date = str(dates.min().date())
    end_date = str(dates.max().date())

    # å§‹ç»ˆåŠ è½½æ—¥é¢‘æ”¶ç›Šç‡: ä»Šæ—¥æ”¶ç›˜ â†’ æ˜æ—¥æ”¶ç›˜
    # Ref($close, -1) æ˜¯æ˜å¤©çš„æ”¶ç›˜ä»· (qlib çš„ Ref è´Ÿæ•°=æœªæ¥)
    ret_df = D.features(
        instruments,
        ["Ref($close, -1)/$close - 1"],
        start_time=start_date,
        end_time=end_date,
    )
    ret_df.columns = ["return"]

    # è½¬ä¸ºå®½è¡¨ (datetime x instrument)
    returns_wide = ret_df["return"].unstack(level="instrument")

    # åªä¿ç•™ norm_df ä¸­å­˜åœ¨çš„æ—¥æœŸ
    common_dates = dates.intersection(returns_wide.index)
    returns_wide = returns_wide.loc[common_dates]

    print(f"æ”¶ç›Šç‡çŸ©é˜µç»´åº¦: {returns_wide.shape} "
          f"(æ—¥æœŸ={returns_wide.shape[0]}, è‚¡ç¥¨={returns_wide.shape[1]})")

    # åŠ è½½åŸºå‡†æ—¥é¢‘æ”¶ç›Šç‡
    try:
        bench_df = D.features(
            ["SH000300"],
            ["$close"],
            start_time=start_date,
            end_time=end_date,
        )
        bench_close = bench_df["$close"]
        # æ—¥é¢‘: ä»Šæ—¥æ”¶ç›˜ â†’ æ˜æ—¥æ”¶ç›˜
        bench_returns = bench_close.pct_change(1).shift(-1)

        # å¯¹é½åˆ°äº¤æ˜“æ—¥æœŸ
        if hasattr(bench_returns.index, "get_level_values"):
            bench_returns.index = bench_returns.index.get_level_values("datetime")
        bench_returns = bench_returns.reindex(common_dates)
        print(f"åŸºå‡†æ”¶ç›ŠåŠ è½½æˆåŠŸ: {len(bench_returns.dropna())} ä¸ªäº¤æ˜“æ—¥")
    except Exception as e:
        print(f"åŸºå‡†æ”¶ç›ŠåŠ è½½å¤±è´¥: {e}ï¼Œä½¿ç”¨ 0 æ›¿ä»£")
        bench_returns = pd.Series(0.0, index=common_dates)

    return returns_wide, bench_returns, common_dates, instruments


def prepare_matrices(norm_df, returns_wide, common_dates):
    """
    å°† DataFrame è½¬æ¢ä¸ºå¯¹é½çš„ NumPy çŸ©é˜µã€‚

    Returns:
        scores_np: dict, model_name -> (T, N) array
        returns_np: (T, N) array
        model_names: list
        date_index: DatetimeIndex
        instrument_index: Index
    """
    print("\n--- æ„å»ºçŸ©é˜µ ---")

    model_names = list(norm_df.columns)

    # å°† norm_df è½¬ä¸º per-model å®½è¡¨
    scores_np = {}
    for model in model_names:
        model_series = norm_df[model]
        model_wide = model_series.unstack(level="instrument")
        # å¯¹é½åˆ°å…¬å…±æ—¥æœŸå’Œè‚¡ç¥¨
        common_instruments = returns_wide.columns.intersection(model_wide.columns)
        model_aligned = model_wide.reindex(
            index=common_dates, columns=common_instruments
        )
        scores_np[model] = model_aligned.values.astype(np.float32)

    # å¯¹é½æ”¶ç›Šç‡çŸ©é˜µ
    common_instruments = returns_wide.columns
    for model in model_names:
        model_wide = norm_df[model].unstack(level="instrument")
        common_instruments = common_instruments.intersection(model_wide.columns)

    returns_aligned = returns_wide[common_instruments].reindex(common_dates)
    returns_np = returns_aligned.values.astype(np.float32)

    # é‡æ–°å¯¹é½ scores
    for model in model_names:
        model_wide = norm_df[model].unstack(level="instrument")
        scores_np[model] = model_wide.reindex(
            index=common_dates, columns=common_instruments
        ).values.astype(np.float32)

    # NaN å¤„ç†ï¼šå°† NaN æ”¶ç›Šç‡è®¾ä¸º 0ï¼ŒNaN åˆ†æ•°è®¾ä¸º -infï¼ˆä¸è¢«é€‰ä¸­ï¼‰
    nan_mask = np.isnan(returns_np)
    returns_np = np.nan_to_num(returns_np, nan=0.0)
    for model in model_names:
        scores_np[model] = np.where(
            nan_mask | np.isnan(scores_np[model]),
            -np.inf,
            scores_np[model],
        )

    print(f"æœ€ç»ˆçŸ©é˜µç»´åº¦: T={returns_np.shape[0]} å¤©, "
          f"N={returns_np.shape[1]} åªè‚¡ç¥¨, "
          f"M={len(model_names)} ä¸ªæ¨¡å‹")

    return scores_np, returns_np, model_names, common_dates, common_instruments


def split_is_oos_by_args(norm_df, args):
    """æ ¹æ®å‚æ•°å°† norm_df åˆ’åˆ†ä¸º IS (In-Sample) å’Œ OOS (Out-of-Sample)"""
    start_date = pd.to_datetime(args.start_date) if args.start_date else None
    
    dates = norm_df.index.get_level_values("datetime").unique().sort_values()
    max_date = dates.max()
    
    cutoff_date = max_date
    if args.exclude_last_years > 0:
        cutoff_date = cutoff_date - pd.DateOffset(years=args.exclude_last_years)
    if args.exclude_last_months > 0:
        cutoff_date = cutoff_date - pd.DateOffset(months=args.exclude_last_months)
        
    end_date = pd.to_datetime(args.end_date) if args.end_date else None
    if end_date and end_date < cutoff_date:
        cutoff_date = end_date
        
    is_mask = norm_df.index.get_level_values("datetime") <= cutoff_date
    if start_date:
        is_mask &= norm_df.index.get_level_values("datetime") >= start_date
        
    is_norm_df = norm_df[is_mask]
    
    oos_mask = norm_df.index.get_level_values("datetime") > cutoff_date
    oos_norm_df = norm_df[oos_mask]
    
    print(f"\n=== æ•°æ®é›†åˆ’åˆ† (In-Sample / Out-Of-Sample) ===")
    if not is_norm_df.empty:
        print(f"IS æœŸ  : {is_norm_df.index.get_level_values('datetime').min().date()} ~ {is_norm_df.index.get_level_values('datetime').max().date()} (å…± {len(is_norm_df.index.get_level_values('datetime').unique())} å¤©)")
    else:
        print("IS æœŸ  : æ— æ•°æ®")
        
    if not oos_norm_df.empty:
        print(f"OOS æœŸ : {oos_norm_df.index.get_level_values('datetime').min().date()} ~ {oos_norm_df.index.get_level_values('datetime').max().date()} (å…± {len(oos_norm_df.index.get_level_values('datetime').unique())} å¤©)")
    else:
        print("OOS æœŸ : æ— æ•°æ®")
        
    return is_norm_df, oos_norm_df


# ============================================================================
# Stage 2: ç›¸å…³æ€§åˆ†æ
# ============================================================================

def correlation_analysis(norm_df, output_dir, anchor_date):
    """è®¡ç®—å¹¶ä¿å­˜é¢„æµ‹å€¼ç›¸å…³æ€§çŸ©é˜µ"""
    print(f"\n{'='*60}")
    print("Stage 2: ç›¸å…³æ€§åˆ†æ")
    print(f"{'='*60}")

    corr_matrix = norm_df.corr()
    print("\n=== æ¨¡å‹é¢„æµ‹ç›¸å…³æ€§çŸ©é˜µ ===")
    print(corr_matrix.round(4))

    # ä¿å­˜
    corr_path = os.path.join(output_dir, f"correlation_matrix_{anchor_date}.csv")
    corr_matrix.to_csv(corr_path)
    print(f"\nç›¸å…³æ€§çŸ©é˜µå·²ä¿å­˜: {corr_path}")

    return corr_matrix


# ============================================================================
# Stage 2.5: æ¨¡å‹åˆ†ç»„ & ç»„åˆç”Ÿæˆ
# ============================================================================

def load_combo_groups(group_config_path, available_models):
    """
    åŠ è½½åˆ†ç»„é…ç½®ï¼ŒéªŒè¯æ¨¡å‹åï¼Œè¿”å›æœ‰æ•ˆåˆ†ç»„ã€‚

    Args:
        group_config_path: combo_groups.yaml è·¯å¾„
        available_models: å½“å‰åŠ è½½åˆ°çš„æ¨¡å‹åˆ—è¡¨ (norm_df.columns)

    Returns:
        groups: dict, group_name -> list of valid model names
    """
    with open(group_config_path, "r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f)

    raw_groups = cfg.get("groups", {})
    if not raw_groups:
        raise ValueError(f"åˆ†ç»„é…ç½®ä¸ºç©º: {group_config_path}")

    available_set = set(available_models)
    groups = {}
    skipped_models = []

    for gname, models in raw_groups.items():
        valid = [m for m in models if m in available_set]
        invalid = [m for m in models if m not in available_set]
        if invalid:
            skipped_models.extend(invalid)
            print(f"  âš ï¸  ç»„ [{gname}] ä¸­ä»¥ä¸‹æ¨¡å‹ä¸å­˜åœ¨äºé¢„æµ‹æ•°æ®ä¸­ï¼Œå·²å¿½ç•¥: {invalid}")
        if valid:
            groups[gname] = valid
        else:
            print(f"  âš ï¸  ç»„ [{gname}] æ— æœ‰æ•ˆæ¨¡å‹ï¼Œå·²è·³è¿‡")

    if skipped_models:
        print(f"  å…±å¿½ç•¥ {len(skipped_models)} ä¸ªæ— æ•ˆæ¨¡å‹")

    # æ£€æŸ¥æœªåˆ†ç»„çš„æ¨¡å‹ (ä»…æ‰“å°æç¤ºï¼Œä¸è‡ªåŠ¨å‚ä¸)
    grouped_models = set()
    for models in groups.values():
        grouped_models.update(models)
    ungrouped = available_set - grouped_models
    if ungrouped:
        print(f"  â„¹ï¸  ä»¥ä¸‹æ¨¡å‹æœªåœ¨ä»»ä½•åˆ†ç»„ä¸­ï¼Œå°†è¢«æ’é™¤: {sorted(ungrouped)}")

    return groups


def generate_grouped_combinations(groups, min_combo_size=1, max_combo_size=0):
    """
    åŸºäºåˆ†ç»„ç”Ÿæˆç»„åˆï¼šä»æ‰€æœ‰ç»„çš„å­é›†ä¸­ï¼Œæ¯ç»„é€‰ä¸€ä¸ªæ¨¡å‹ï¼Œåšç¬›å¡å°”ç§¯ã€‚

    ä¸ºæ”¯æŒ min/max combo sizeï¼Œæˆ‘ä»¬æšä¸¾ç»„çš„å­é›†ï¼ˆé€‰å“ªäº›ç»„å‚ä¸ï¼‰ï¼Œ
    ç„¶åå¯¹å‚ä¸çš„ç»„åš itertools.productã€‚

    Args:
        groups: dict, group_name -> list of models
        min_combo_size: æœ€å°ç»„åˆå¤§å° (é€‰å‡ ä¸ªç»„)
        max_combo_size: æœ€å¤§ç»„åˆå¤§å° (0=å…¨éƒ¨ç»„)

    Returns:
        list of tuples, æ¯ä¸ª tuple æ˜¯ä¸€ä¸ªæ¨¡å‹ç»„åˆ
    """
    group_names = list(groups.keys())
    n_groups = len(group_names)
    max_size = max_combo_size if max_combo_size > 0 else n_groups
    max_size = min(max_size, n_groups)

    all_combinations = []

    # æšä¸¾é€‰å“ªäº›ç»„å‚ä¸ (é€‰ r ä¸ªç»„çš„ç»„åˆ)
    for r in range(min_combo_size, max_size + 1):
        for group_subset in itertools.combinations(group_names, r):
            # å¯¹é€‰ä¸­çš„ç»„åšç¬›å¡å°”ç§¯
            model_lists = [groups[g] for g in group_subset]
            for combo in itertools.product(*model_lists):
                all_combinations.append(combo)

    return all_combinations


# ============================================================================
# Stage 3: å‘é‡åŒ–å¿«é€Ÿå›æµ‹ (æ ¸å¿ƒ)
# ============================================================================

def _vectorized_topk_backtest_single(
    combo_score_np, returns_np, top_k, cost_rate, rebalance_freq=5,
):
    """
    å¯¹å•ä¸ªç»„åˆè¿›è¡Œå‘é‡åŒ–å›æµ‹ â€” å‘¨é¢‘è°ƒä»“ + æ—¥é¢‘å‡€å€¼ã€‚

    æ¨¡æ‹Ÿ qlib çš„ TopkDropoutStrategy + SimulatorExecutor è¡Œä¸ºï¼š
    - æ¯ rebalance_freq ä¸ªäº¤æ˜“æ—¥åšä¸€æ¬¡ TopK é€‰è‚¡ï¼ˆè°ƒä»“ï¼‰
    - éè°ƒä»“æ—¥ä¿æŒä¸Šä¸€æœŸçš„æŒä»“ä¸å˜
    - æ¯ä¸ªäº¤æ˜“æ—¥æŒ‰æ—¥é¢‘æ”¶ç›Šç‡æ›´æ–°ç»„åˆæ”¶ç›Š
    - æ¢æ‰‹è´¹ç”¨ä»…åœ¨è°ƒä»“æ—¥æ‰£é™¤

    Args:
        combo_score_np: (T, N) èåˆä¿¡å·çŸ©é˜µ
        returns_np: (T, N) æ—¥é¢‘æ”¶ç›Šç‡çŸ©é˜µ
        top_k: TopK æŒä»“æ•°
        cost_rate: å•æ¬¡æ¢æ‰‹äº¤æ˜“è´¹ç”¨ç‡
        rebalance_freq: è°ƒä»“é¢‘ç‡(äº¤æ˜“æ—¥æ•°), week=5, day=1

    Returns:
        numpy array: (T,) æ¯æ—¥å‡€æ”¶ç›Šç‡åºåˆ—
    """
    T, N = combo_score_np.shape
    k = min(top_k, N)

    # é¢„è®¡ç®—æ¯å¤©çš„ TopKï¼ˆä»…åœ¨è°ƒä»“æ—¥è®¡ç®—ï¼ŒèŠ‚çœ argpartition å¼€é”€ï¼‰
    rebalance_indices = xp.arange(0, T, rebalance_freq)
    combo_score_reb = combo_score_np[rebalance_indices]
    topk_reb = xp.argpartition(-combo_score_reb, k, axis=1)[:, :k]

    # å°†è°ƒä»“æ—¥çš„æŒä»“å¹¿æ’­åˆ°æ¯ä¸€å¤©: day_to_reb_idx å°† [0..T-1] æ˜ å°„åˆ°ç›¸åº”çš„è°ƒä»“æœŸç´¢å¼•
    day_to_reb_idx = xp.arange(T) // rebalance_freq
    actual_holdings = topk_reb[day_to_reb_idx]

    # æ¯å¤©éƒ½ç”¨å½“å‰æŒä»“è®¡ç®—æ—¥æ”¶ç›Š
    row_indices = xp.arange(T)[:, None]
    daily_returns = xp.mean(returns_np[row_indices, actual_holdings], axis=1)

    turnover_costs = xp.zeros(T, dtype=xp.float32)

    # è®¡ç®—æ¢æ‰‹è´¹ç”¨ï¼ˆä»…åœ¨æœ‰ä¸¤ä¸ªåŠä»¥ä¸Šè°ƒä»“æœŸæ—¶æ‰å¯èƒ½æœ‰æ¢æ‰‹ï¼‰
    if cost_rate > 0 and len(rebalance_indices) > 1:
        # ä»…é’ˆå¯¹è°ƒä»“æ—¥æ„å»º boolean mask æ¥è®¡ç®—é›†åˆå·®é›†
        mask_reb = xp.zeros((len(rebalance_indices), N), dtype=bool)
        row_indices_reb = xp.arange(len(rebalance_indices))[:, None]
        mask_reb[row_indices_reb, topk_reb] = True
        
        # curr & ~prev å³ä¸ºæ–°å¢æŒä»“
        mask_curr = mask_reb[1:]
        mask_prev = mask_reb[:-1]
        
        turnovers = xp.sum(mask_curr & ~mask_prev, axis=1) / k
        # å°†æ¢æ‰‹è´¹ç”¨è®°å½•åœ¨å‘ç”Ÿè°ƒä»“çš„å½“å¤© (ç´¢å¼• 1 å¼€å§‹çš„ rebalance_indices)
        turnover_costs[rebalance_indices[1:]] = turnovers * cost_rate

    # æ‰£é™¤äº¤æ˜“è´¹ç”¨
    net_returns = daily_returns - turnover_costs

    return _to_numpy(net_returns)


def _vectorized_topk_backtest_batch(
    combo_scores_batch, returns_np, top_k, cost_rate, rebalance_freq=5,
):
    """
    æ‰¹é‡å‘é‡åŒ–å›æµ‹ï¼ˆå¤šä¸ªç»„åˆåŒæ—¶å¤„ç†ï¼‰ã€‚

    Args:
        combo_scores_batch: list of (T, N) arrays - å¤šä¸ªç»„åˆçš„èåˆä¿¡å·
        returns_np: (T, N) æ—¥é¢‘æ”¶ç›Šç‡çŸ©é˜µ
        top_k: TopK
        cost_rate: äº¤æ˜“è´¹ç”¨ç‡
        rebalance_freq: è°ƒä»“é¢‘ç‡(äº¤æ˜“æ—¥æ•°)

    Returns:
        list of numpy arrays: æ¯ä¸ªç»„åˆçš„æ—¥é¢‘å‡€æ”¶ç›Šç‡åºåˆ—
    """
    results = []
    for combo_score in combo_scores_batch:
        ret = _vectorized_topk_backtest_single(
            combo_score, returns_np, top_k, cost_rate, rebalance_freq,
        )
        results.append(ret)
    return results


def compute_metrics(net_returns, bench_returns_np, freq="day"):
    """
    ä»æ—¥é¢‘å‡€æ”¶ç›Šç‡åºåˆ—è®¡ç®—ç»©æ•ˆæŒ‡æ ‡ã€‚

    æ³¨æ„ï¼šnet_returns ç¾åœ¨å§‹ç»ˆæ˜¯æ—¥é¢‘çš„ï¼ˆå³ä½¿æ˜¯å‘¨é¢‘è°ƒä»“ç­–ç•¥ï¼‰ï¼Œ
    å› ä¸ºæˆ‘ä»¬åœ¨å›æµ‹å¼•æ“ä¸­æŒ‰æ—¥ç´¯è®¡å‡€å€¼ã€‚periods å›ºå®šä¸º 252ã€‚

    Args:
        net_returns: (T,) æ—¥é¢‘ç»„åˆå‡€æ”¶ç›Šç‡
        bench_returns_np: (T,) æ—¥é¢‘åŸºå‡†æ”¶ç›Šç‡
        freq: ä¿ç•™å‚æ•°ï¼Œå§‹ç»ˆä½¿ç”¨ 252 (æ—¥é¢‘)

    Returns:
        dict: æŒ‡æ ‡å­—å…¸
    """
    # æ”¶ç›Šç‡åºåˆ—å§‹ç»ˆæ˜¯æ—¥é¢‘ï¼Œç”¨ 252 å¹´åŒ–
    periods = 252

    # å‡€å€¼æ›²çº¿
    nav = np.cumprod(1 + net_returns)
    final_nav = nav[-1] if len(nav) > 0 else 1.0
    total_ret = final_nav - 1.0

    # å¹´åŒ–æ”¶ç›Š
    ann_ret = np.mean(net_returns) * periods

    # æœ€å¤§å›æ’¤
    running_max = np.maximum.accumulate(nav)
    drawdown = (nav - running_max) / running_max
    max_dd = np.min(drawdown)

    # åŸºå‡†æ”¶ç›Š
    bench_ret_total = np.prod(1 + bench_returns_np) - 1.0

    # è¶…é¢
    excess_ret = total_ret - bench_ret_total
    ann_excess = ann_ret - (np.mean(bench_returns_np) * periods)

    # Calmar
    calmar = ann_ret / abs(max_dd) if max_dd != 0 else 0

    # Sharpe (ç®€åŒ–ç‰ˆ)
    if np.std(net_returns) > 0:
        sharpe = np.mean(net_returns) / np.std(net_returns) * np.sqrt(periods)
    else:
        sharpe = 0

    return {
        "Ann_Ret": ann_ret,
        "Max_DD": max_dd,
        "Excess_Ret": excess_ret,
        "Ann_Excess": ann_excess,
        "Total_Ret": total_ret,
        "Final_NAV": final_nav * BACKTEST_CONFIG["account"],
        "Calmar": calmar,
        "Sharpe": sharpe,
    }


def brute_force_fast_backtest(
    scores_np, returns_np, model_names, bench_returns_np,
    top_k, freq, cost_rate, batch_size,
    min_combo_size, max_combo_size, output_dir, anchor_date,
    resume=False, rebalance_freq=5, use_groups=False, group_config=None,
):
    """
    å‘é‡åŒ–å¿«é€Ÿæš´åŠ›ç©·ä¸¾æ‰€æœ‰æ¨¡å‹ç»„åˆå¹¶å›æµ‹ã€‚

    Returns:
        results_df: DataFrameï¼Œæ‰€æœ‰ç»„åˆçš„å›æµ‹ç»“æœ
    """
    print(f"\n{'='*60}")
    print("Stage 3: å‘é‡åŒ–å¿«é€Ÿå›æµ‹")
    print(f"{'='*60}")

    max_size = max_combo_size if max_combo_size > 0 else len(model_names)
    max_size = min(max_size, len(model_names))

    # â”€â”€ ç”Ÿæˆç»„åˆ â”€â”€
    if use_groups and group_config:
        print(f"\nğŸ“¦ åˆ†ç»„ç©·ä¸¾æ¨¡å¼ (é…ç½®: {group_config})")
        groups = load_combo_groups(group_config, model_names)
        print(f"æœ‰æ•ˆåˆ†ç»„ ({len(groups)}ä¸ª):")
        total_product = 1
        for gname, models in groups.items():
            print(f"  [{gname}] ({len(models)}ä¸ª): {models}")
            total_product *= len(models)

        all_combinations = generate_grouped_combinations(
            groups, min_combo_size, max_combo_size
        )
        print(f"\nåˆ†ç»„ç¬›å¡å°”ç§¯ç»„åˆæ•°: {len(all_combinations)}")
    else:
        print(f"å¾…ç©·ä¸¾æ¨¡å‹ ({len(model_names)}ä¸ª): {model_names}")
        print(f"ç»„åˆå¤§å°èŒƒå›´: {min_combo_size} ~ {max_size}")
        all_combinations = []
        for r in range(min_combo_size, max_size + 1):
            all_combinations.extend(itertools.combinations(model_names, r))

    print(f"è°ƒä»“é¢‘ç‡: æ¯ {rebalance_freq} ä¸ªäº¤æ˜“æ—¥, TopK={top_k}")
    print(f"äº¤æ˜“è´¹ç”¨ç‡: {cost_rate:.4f}")
    print(f"æ‰¹å¤„ç†å¤§å°: {batch_size}")
    print(f"æ”¶ç›Šç‡: æ—¥é¢‘, å‡€å€¼: æ—¥é¢‘ç´¯è®¡")
    print(f"è®¡ç®—åç«¯: {'CuPy (GPU)' if _USE_GPU else 'NumPy (CPU)'}")

    print(f"æ€»ç»„åˆæ•°: {len(all_combinations)}")

    # Resume: åŠ è½½å·²æœ‰ç»“æœ
    csv_path = os.path.join(output_dir, f"brute_force_fast_results_{anchor_date}.csv")
    done_combos = set()
    existing_results = []

    if resume and os.path.exists(csv_path):
        existing_df = pd.read_csv(csv_path)
        existing_results = existing_df.to_dict("records")
        done_combos = set(existing_df["models"].tolist())
        print(f"Resume æ¨¡å¼: å·²æœ‰ {len(done_combos)} ä¸ªç»„åˆï¼Œè·³è¿‡")

    # è¿‡æ»¤å·²å®Œæˆçš„ç»„åˆ
    pending = [
        c for c in all_combinations if ",".join(c) not in done_combos
    ]
    print(f"å¾…å›æµ‹ç»„åˆæ•°: {len(pending)}")

    if not pending:
        print("æ‰€æœ‰ç»„åˆå·²å®Œæˆï¼")
        results_df = pd.DataFrame(existing_results)
    else:
        # å°†æ•°æ®ç§»åˆ° GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰
        returns_gpu = xp.asarray(returns_np)
        scores_gpu = {m: xp.asarray(v) for m, v in scores_np.items()}

        results = list(existing_results)
        t0 = time.time()

        # åˆ†æ‰¹å¤„ç†
        for batch_start in tqdm(
            range(0, len(pending), batch_size),
            desc="Fast Backtesting",
            total=(len(pending) + batch_size - 1) // batch_size,
        ):
            batch_combos = pending[batch_start : batch_start + batch_size]

            # ä¸ºæ¯ä¸ªç»„åˆè®¡ç®—èåˆä¿¡å·
            batch_scores = []
            for combo in batch_combos:
                # ç­‰æƒèåˆ
                combo_score = sum(scores_gpu[m] for m in combo) / len(combo)
                batch_scores.append(combo_score)

            # æ‰¹é‡å›æµ‹
            batch_returns = _vectorized_topk_backtest_batch(
                batch_scores, returns_gpu, top_k, cost_rate, rebalance_freq,
            )

            # è®¡ç®—æŒ‡æ ‡
            for combo, net_ret in zip(batch_combos, batch_returns):
                metrics = compute_metrics(net_ret, bench_returns_np, freq)
                metrics["models"] = ",".join(combo)
                metrics["n_models"] = len(combo)
                results.append(metrics)

            # å®šæœŸä¿å­˜ & GC
            if (batch_start // batch_size) % 10 == 0 and batch_start > 0:
                gc.collect()

        elapsed = time.time() - t0
        speed = len(pending) / elapsed if elapsed > 0 else 0
        print(f"\nå›æµ‹é€Ÿåº¦: {speed:.1f} ç»„åˆ/ç§’ (å…± {elapsed:.1f} ç§’)")

        # æ¸…ç† GPU å†…å­˜
        if _USE_GPU:
            del returns_gpu, scores_gpu
            import cupy as cp
            cp.get_default_memory_pool().free_all_blocks()

        results_df = pd.DataFrame(results)

    # æ’åºå¹¶ä¿å­˜
    if not results_df.empty:
        results_df = results_df.sort_values(
            by="Ann_Excess", ascending=False
        ).reset_index(drop=True)
        results_df.to_csv(csv_path, index=False)
        print(f"\nç©·ä¸¾å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {csv_path}")
        print(f"æœ‰æ•ˆç»„åˆæ•°: {len(results_df)}")
    else:
        print("è­¦å‘Š: æ— æœ‰æ•ˆå›æµ‹ç»“æœ")

    return results_df


# ============================================================================
# Stage 4: ç»“æœåˆ†æ (å¤ç”¨åŸç‰ˆé€»è¾‘)
# ============================================================================

def analyze_results(
    results_df, corr_matrix, norm_df, train_records, output_dir, anchor_date, top_n=50,
):
    """å¯¹æš´åŠ›ç©·ä¸¾ç»“æœè¿›è¡Œå…¨é¢åˆ†æ"""
    import matplotlib
    matplotlib.use("Agg")
    import matplotlib.pyplot as plt
    import seaborn as sns

    print(f"\n{'='*60}")
    print("Stage 4: ç»“æœåˆ†æ")
    print(f"{'='*60}")

    if results_df.empty:
        print("æ— æ•°æ®å¯åˆ†æï¼")
        return

    # é¢„å¤„ç†
    df = results_df.copy()
    df["model_list"] = df["models"].apply(lambda x: x.split(","))
    df["is_single"] = df["n_models"] == 1

    report_lines = []  # æ”¶é›†æŠ¥å‘Šæ–‡æœ¬

    # -----------------------------------------------------------------------
    # 4.1 Top ç»„åˆå±•ç¤º
    # -----------------------------------------------------------------------
    display_cols = ["models", "n_models", "Ann_Ret", "Max_DD", "Ann_Excess", "Calmar"]
    available_cols = [c for c in display_cols if c in df.columns]
    fmt = {
        "Ann_Ret": "{:.2%}".format,
        "Max_DD": "{:.2%}".format,
        "Ann_Excess": "{:.2%}".format,
        "Calmar": "{:.2f}".format,
    }
    fmt = {k: v for k, v in fmt.items() if k in df.columns}

    print("\nğŸ† === ç»¼åˆè¡¨ç°æœ€ä½³ Top 20 (æŒ‰å¹´åŒ–è¶…é¢) ===")
    top20_str = df[available_cols].head(20).to_string(formatters=fmt)
    print(top20_str)
    report_lines.append("=== Top 20 (æŒ‰å¹´åŒ–è¶…é¢) ===\n" + top20_str)

    robust_df = df[df["Ann_Ret"] > 0.10].sort_values(by="Max_DD", ascending=False)
    if not robust_df.empty:
        print("\nğŸ›¡ï¸ === æœ€ç¨³å¥ç»„åˆ Top 10 (å¹´åŒ–>10%, æŒ‰å›æ’¤æ’åº) ===")
        robust_str = robust_df[available_cols].head(10).to_string(formatters=fmt)
        print(robust_str)
        report_lines.append("\n=== æœ€ç¨³å¥ç»„åˆ Top 10 ===\n" + robust_str)

    # -----------------------------------------------------------------------
    # 4.2 æ¨¡å‹å½’å› åˆ†æ (Model Attribution)
    # -----------------------------------------------------------------------
    print(f"\nğŸ“Š === æ¨¡å‹å½’å› åˆ†æ (Top/Bottom {top_n}) ===")

    top_combinations = df.sort_values("Calmar", ascending=False).head(top_n)
    bottom_combinations = df.sort_values("Calmar", ascending=True).head(top_n)

    def get_model_counts(series_of_lists):
        all_models = list(chain.from_iterable(series_of_lists))
        return pd.Series(Counter(all_models)).sort_values(ascending=False)

    top_counts = get_model_counts(top_combinations["model_list"])
    bottom_counts = get_model_counts(bottom_combinations["model_list"])

    attribution = pd.DataFrame(
        {"Top_Count": top_counts, "Bottom_Count": bottom_counts}
    ).fillna(0)
    attribution["Net_Score"] = attribution["Top_Count"] - attribution["Bottom_Count"]
    attribution = attribution.sort_values("Net_Score", ascending=False)

    print(attribution)
    report_lines.append("\n=== æ¨¡å‹å½’å›  (Net Score) ===\n" + attribution.to_string())

    attr_path = os.path.join(output_dir, f"model_attribution_{anchor_date}.csv")
    attribution.to_csv(attr_path)
    print(f"å½’å› è¡¨å·²ä¿å­˜: {attr_path}")

    # å½’å› æ¡å½¢å›¾
    try:
        fig, ax = plt.subplots(figsize=(14, 6))
        x = np.arange(len(attribution))
        width = 0.35
        ax.bar(
            x - width / 2, attribution["Top_Count"], width,
            label=f"In Top {top_n}", color="forestgreen", alpha=0.7,
        )
        ax.bar(
            x + width / 2, attribution["Bottom_Count"], width,
            label=f"In Bottom {top_n}", color="firebrick", alpha=0.7,
        )
        ax.set_xticks(x)
        ax.set_xticklabels(attribution.index, rotation=45, ha="right")
        ax.set_ylabel("Frequency")
        ax.set_title(
            f"Model Importance Analysis (Top/Bottom {top_n} by Calmar) [FAST]"
        )
        ax.legend()
        plt.tight_layout()
        attr_fig_path = os.path.join(
            output_dir, f"model_attribution_{anchor_date}.png"
        )
        plt.savefig(attr_fig_path, dpi=150)
        plt.close()
        print(f"å½’å› å›¾å·²ä¿å­˜: {attr_fig_path}")
    except Exception as e:
        print(f"å½’å› å›¾ç»˜åˆ¶å¤±è´¥: {e}")

    # -----------------------------------------------------------------------
    # 4.3 ç›¸å…³æ€§ vs ç»©æ•ˆåˆ†æ
    # -----------------------------------------------------------------------
    print("\nğŸ”— === ç›¸å…³æ€§ vs ç»©æ•ˆåˆ†æ ===")

    # æå–å•æ¨¡å‹è¡¨ç°
    single_model_perf = (
        df[df["n_models"] == 1].set_index("models")["Ann_Excess"].to_dict()
    )

    # ä½¿ç”¨åŸºäº unique ç»„åˆçš„é¢„å…ˆè®¡ç®—ï¼Œé¿å… 100ä¸‡è¡Œ çš„ row-by-row pd.apply
    unique_combos = df["models"].unique()
    combo_to_metrics = {}

    for combo_str in unique_combos:
        models_list = combo_str.split(",")
        n = len(models_list)

        # ç»„åˆå†…éƒ¨å¹³å‡ç›¸å…³æ€§
        if n < 2:
            avg_corr = 1.0
        else:
            try:
                sub = corr_matrix.loc[models_list, models_list].values
                # ä½¿ç”¨ numpy triu æå–ä¸Šä¸‰è§’ï¼ˆä¸å«å¯¹è§’çº¿ï¼‰
                upper_tri = sub[np.triu_indices(n, k=1)]
                avg_corr = np.mean(upper_tri) if len(upper_tri) > 0 else 1.0
            except KeyError:
                avg_corr = np.nan

        # å¤šæ ·æ€§çº¢åˆ©
        avg_individual_ret = np.mean(
            [single_model_perf.get(m, np.nan) for m in models_list]
        )
        combo_to_metrics[combo_str] = (avg_corr, avg_individual_ret)

    # æ˜ å°„å› DataFrame
    metrics_df = pd.DataFrame.from_dict(
        combo_to_metrics, orient="index", columns=["avg_corr", "avg_ind"]
    )
    
    # å°†æŒ‡æ ‡ merge è¿›åŸè¡¨
    df = df.merge(metrics_df, left_on="models", right_index=True, how="left")
    df["diversity_bonus"] = df["Ann_Excess"] - df["avg_ind"]
    df = df.drop(columns=["avg_ind"])

    # æ‰¾é»„é‡‘ç»„åˆ
    golden = df[
        (df["avg_corr"] < 0.3) & (df["Calmar"] > df["Calmar"].quantile(0.9))
    ]
    if not golden.empty:
        print(
            f"å‘ç° {len(golden)} ä¸ª'é»„é‡‘ç»„åˆ'ï¼šå†…éƒ¨ç›¸å…³æ€§ < 0.3 ä¸” Calmar å‰ 10%"
        )
        print(f"å…¸å‹ä»£è¡¨: {golden.iloc[0]['models']}")
        golden_cols = [c for c in available_cols + ["avg_corr"] if c in df.columns]
        report_lines.append(
            f"\n=== é»„é‡‘ç»„åˆ ({len(golden)} ä¸ª) ===\n"
            + golden[golden_cols].head(5).to_string(formatters=fmt)
        )
    else:
        print("æœªå‘ç°æ˜¾è‘—çš„'ä½ç›¸å…³æ€§-é«˜æ”¶ç›Š'ç»„åˆ")
        report_lines.append("\n=== é»„é‡‘ç»„åˆ: æœªå‘ç° ===")

    # ç›¸å…³æ€§ vs Calmar æ•£ç‚¹å›¾
    try:
        multi_df = df[df["n_models"] > 1].dropna(subset=["avg_corr"])
        if not multi_df.empty:
            # é˜²å†…å­˜æº¢å‡ºï¼šå¦‚æœç»„åˆè¶…è¿‡ 50,000ï¼ŒéšæœºæŠ½æ · 50,000 è¿›è¡Œç»˜å›¾
            MAX_PLOT_POINTS = 50000
            if len(multi_df) > MAX_PLOT_POINTS:
                print(f"æ•°æ®é‡è¿‡å¤§ ({len(multi_df)})ï¼ŒéšæœºæŠ½æ · {MAX_PLOT_POINTS} ä¸ªç‚¹è¿›è¡Œç»˜å›¾")
                plot_df = multi_df.sample(n=MAX_PLOT_POINTS, random_state=42)
            else:
                plot_df = multi_df

            fig, axes = plt.subplots(1, 2, figsize=(18, 8))

            # å›¾1: é£é™©-æ”¶ç›Šå…¨æ™¯å›¾
            scatter = axes[0].scatter(
                plot_df["Max_DD"].abs(), plot_df["Ann_Excess"],
                c=plot_df["n_models"], cmap="viridis", alpha=0.6,
                s=plot_df["n_models"] * 10 + 20,
            )
            singles = df[df["n_models"] == 1]
            axes[0].scatter(
                singles["Max_DD"].abs(), singles["Ann_Excess"],
                color="red", marker="x", s=100, label="Single Model",
            )
            axes[0].set_xlabel("Max Drawdown (Absolute)")
            axes[0].set_ylabel("Ann Excess Return")
            axes[0].set_title("Risk vs Return [FAST]")
            axes[0].legend()
            plt.colorbar(scatter, ax=axes[0], label="# Models")

            # å›¾2: ç›¸å…³æ€§ vs Calmar
            sns.scatterplot(
                x="avg_corr", y="Calmar", hue="n_models",
                palette="viridis", data=plot_df, ax=axes[1], alpha=0.7,
            )
            sns.regplot(
                x="avg_corr", y="Calmar", data=plot_df,
                scatter=False, ax=axes[1], color="red",
                line_kws={"linestyle": "--"},
            )
            axes[1].set_title("Correlation vs Calmar [FAST]")
            axes[1].set_xlabel("Avg Intra-Ensemble Correlation")

            plt.tight_layout()
            scatter_path = os.path.join(
                output_dir, f"risk_return_scatter_{anchor_date}.png"
            )
            plt.savefig(scatter_path, dpi=150)
            plt.close()
            print(f"æ•£ç‚¹å›¾å·²ä¿å­˜: {scatter_path}")
    except Exception as e:
        print(f"æ•£ç‚¹å›¾ç»˜åˆ¶å¤±è´¥: {e}")

    # æ¨¡å‹æ•°é‡åˆ†ç»„ç»Ÿè®¡
    group_stats = df.groupby("n_models")[["Ann_Excess", "Calmar"]].agg(
        ["median", "mean", "max"]
    )
    print("\n=== æŒ‰æ¨¡å‹æ•°é‡åˆ†ç»„ç»Ÿè®¡ ===")
    print(group_stats.round(4))
    report_lines.append(
        "\n=== æŒ‰æ¨¡å‹æ•°é‡åˆ†ç»„ç»Ÿè®¡ ===\n" + group_stats.round(4).to_string()
    )

    # -----------------------------------------------------------------------
    # 4.4 Portfolio Optimization (Top 10 å•æ¨¡å‹)
    # -----------------------------------------------------------------------
    print("\nğŸ“ === ä¼˜åŒ–æƒé‡åˆ†æ ===")
    try:
        from scipy.optimize import minimize

        # ä½¿ç”¨ norm_df çš„æ—¥å‡å€¼ä½œä¸ºç®€åŒ–æ”¶ç›Šä»£ç†
        top_singles = (
            df[df["n_models"] == 1]
            .sort_values("Calmar", ascending=False)
            .head(10)["models"]
            .tolist()
        )

        valid_models = [m for m in top_singles if m in norm_df.columns]

        if len(valid_models) >= 2:
            # ä½¿ç”¨é¢„æµ‹å€¼æ’åçš„ TopK æ”¶ç›Šä½œä¸ºè¿‘ä¼¼æ”¶ç›Š
            print(f"ä½¿ç”¨ {len(valid_models)} ä¸ª Top å•æ¨¡å‹è¿›è¡Œä¼˜åŒ–")

            # ä» norm_df ç›´æ¥è®¡ç®—ç›¸å…³æ€§å’Œ variance è¿›è¡Œä¼˜åŒ–
            subset_corr = norm_df[valid_models].corr()
            # ä½¿ç”¨å•æ¨¡å‹å›æµ‹ç»“æœæ„é€ æ”¶ç›Šå‘é‡
            mu = pd.Series(
                {m: df[df["models"] == m]["Ann_Excess"].values[0] for m in valid_models}
            )
            # ç®€åŒ– covï¼šä½¿ç”¨ corr * vol
            individual_vol = pd.Series(
                {m: abs(df[df["models"] == m]["Max_DD"].values[0]) for m in valid_models}
            )
            cov = subset_corr * np.outer(individual_vol.values, individual_vol.values)

            num = len(valid_models)
            init_guess = [1.0 / num] * num
            constraints = {"type": "eq", "fun": lambda x: np.sum(x) - 1}
            bounds = tuple((0.0, 1.0) for _ in range(num))

            # Max Sharpe
            def neg_sharpe(w, mu, cov):
                ret = np.dot(w, mu)
                vol = np.sqrt(np.dot(w.T, np.dot(cov.values, w)))
                return -(ret / (vol + 1e-9))

            opt_sharpe = minimize(
                neg_sharpe, init_guess, args=(mu, cov),
                method="SLSQP", bounds=bounds, constraints=constraints,
            )

            # Risk Parity
            def risk_parity_obj(w, cov):
                w = np.array(w)
                port_vol = np.sqrt(np.dot(w.T, np.dot(cov.values, w)))
                mrc = np.dot(cov.values, w) / (port_vol + 1e-9)
                rc = w * mrc
                target = port_vol / len(w)
                return np.sum((rc - target) ** 2)

            opt_rp = minimize(
                risk_parity_obj, init_guess, args=(cov,),
                method="SLSQP", bounds=bounds, constraints=constraints,
            )

            weights_df = pd.DataFrame(
                {
                    "Equal_Weight": init_guess,
                    "Max_Sharpe": opt_sharpe.x,
                    "Risk_Parity": opt_rp.x,
                },
                index=valid_models,
            )

            print("\n=== æ™ºèƒ½ä¼˜åŒ–æƒé‡å¯¹æ¯” ===")
            print(weights_df.round(4))
            report_lines.append(
                "\n=== ä¼˜åŒ–æƒé‡å¯¹æ¯” ===\n" + weights_df.round(4).to_string()
            )

            opt_path = os.path.join(
                output_dir, f"optimization_weights_{anchor_date}.csv"
            )
            weights_df.to_csv(opt_path)
            print(f"ä¼˜åŒ–æƒé‡å·²ä¿å­˜: {opt_path}")

        else:
            print("æœ‰æ•ˆæ¨¡å‹ä¸è¶³ 2 ä¸ªï¼Œè·³è¿‡ä¼˜åŒ–")
    except Exception as e:
        print(f"ä¼˜åŒ–åˆ†æå¤±è´¥: {e}")

    # -----------------------------------------------------------------------
    # 4.5 ç»¼åˆæŠ¥å‘Š
    # -----------------------------------------------------------------------
    best_combo = df.iloc[0]
    best_diversity_idx = df["diversity_bonus"].idxmax() if "diversity_bonus" in df.columns else None
    best_diversity = df.loc[best_diversity_idx] if best_diversity_idx is not None and pd.notna(best_diversity_idx) else None

    summary = []
    summary.append("=" * 60)
    summary.append("âš¡ å¿«é€Ÿæ¨¡å¼è‡ªåŠ¨åˆ†ææŠ¥å‘Šæ‘˜è¦")
    summary.append("=" * 60)
    summary.append("(æ³¨æ„ï¼šå¿«é€Ÿæ¨¡å¼æŒ‡æ ‡ä¸ºè¿‘ä¼¼å€¼ï¼Œæ’åºä¸åŸç‰ˆé«˜åº¦ä¸€è‡´)")

    summary.append(f"\n1. æœ€ä½³ç»„åˆ (å¹´åŒ–è¶…é¢):")
    summary.append(f"   æ¨¡å‹: {best_combo['models']}")
    summary.append(f"   æ¨¡å‹æ•°: {best_combo['n_models']}")
    summary.append(f"   å¹´åŒ–æ”¶ç›Š: {best_combo['Ann_Ret']:.2%}")
    summary.append(f"   å¹´åŒ–è¶…é¢: {best_combo['Ann_Excess']:.2%}")
    summary.append(f"   æœ€å¤§å›æ’¤: {best_combo['Max_DD']:.2%}")
    summary.append(f"   Calmar: {best_combo['Calmar']:.2f}")

    if "avg_corr" in best_combo.index and pd.notna(best_combo.get("avg_corr")):
        summary.append(f"   å†…éƒ¨ç›¸å…³æ€§: {best_combo['avg_corr']:.4f}")

    if best_diversity is not None and pd.notna(best_diversity.get("diversity_bonus")):
        summary.append(f"\n2. æœ€å¤§å¤šæ ·æ€§çº¢åˆ©ç»„åˆ:")
        summary.append(f"   æ¨¡å‹: {best_diversity['models']}")
        summary.append(f"   Diversity Bonus: {best_diversity['diversity_bonus']:.4%}")

    summary.append(f"\n3. å»ºè®®ä¿ç•™çš„æ ¸å¿ƒæ¨¡å‹ (MVP):")
    summary.append(f"   {attribution.index[:3].tolist()}")
    summary.append("=" * 60)

    summary_text = "\n".join(summary)
    print(f"\n{summary_text}")

    # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
    report_path = os.path.join(output_dir, f"analysis_report_fast_{anchor_date}.txt")
    full_report = summary_text + "\n\n" + "\n".join(report_lines)
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(full_report)
    print(f"\nå®Œæ•´æŠ¥å‘Šå·²ä¿å­˜: {report_path}")


# ============================================================================
# Main
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="âš¡ å¿«é€Ÿå‘é‡åŒ–æš´åŠ›ç©·ä¸¾ç»„åˆå›æµ‹ + ç»“æœåˆ†æ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¿«é€Ÿæµ‹è¯• (æœ€å¤š 3 ä¸ªæ¨¡å‹)
  python engine/scripts/brute_force_fast.py --max-combo-size 3

  # ä»…åˆ†æå·²æœ‰ç»“æœ
  python engine/scripts/brute_force_fast.py --analysis-only

  # å®Œæ•´ç©·ä¸¾ + åˆ†æ
  python engine/scripts/brute_force_fast.py

  # ä½¿ç”¨ GPU åŠ é€Ÿ
  python engine/scripts/brute_force_fast.py --use-gpu

  # ä»ä¸­æ–­å¤„ç»§ç»­
  python engine/scripts/brute_force_fast.py --resume
        """,
    )
    parser.add_argument(
        "--record-file", type=str, default="latest_train_records.json",
        help="è®­ç»ƒè®°å½•æ–‡ä»¶è·¯å¾„ (é»˜è®¤: latest_train_records.json)",
    )
    parser.add_argument(
        "--max-combo-size", type=int, default=0,
        help="æœ€å¤§ç»„åˆå¤§å° (0=å…¨éƒ¨, é»˜è®¤: 0)",
    )
    parser.add_argument(
        "--min-combo-size", type=int, default=1,
        help="æœ€å°ç»„åˆå¤§å° (é»˜è®¤: 1)",
    )
    parser.add_argument(
        "--freq", type=str, default="week", choices=["day", "week"],
        help="å›æµ‹äº¤æ˜“é¢‘ç‡ (é»˜è®¤: week)",
    )
    parser.add_argument(
        "--top-n", type=int, default=50,
        help="åˆ†ææ—¶ Top/Bottom N (é»˜è®¤: 50)",
    )
    parser.add_argument(
        "--output-dir", type=str, default="output/brute_force_fast",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: output/brute_force_fast)",
    )
    parser.add_argument(
        "--resume", action="store_true",
        help="ä»å·²æœ‰ CSV ç»§ç»­ (è·³è¿‡å·²å®Œæˆçš„ç»„åˆ)",
    )
    parser.add_argument(
        "--start-date", type=str, default=None,
        help="å›æµ‹å¼€å§‹æ—¥æœŸ YYYY-MM-DD",
    )
    parser.add_argument(
        "--end-date", type=str, default=None,
        help="å›æµ‹ç»“æŸæ—¥æœŸ YYYY-MM-DD",
    )
    parser.add_argument(
        "--exclude-last-years", type=int, default=0,
        help="åœ¨ IS é˜¶æ®µæ’é™¤æœ€å N å¹´çš„æ•°æ®ï¼ˆç•™ä½œ OOSï¼‰",
    )
    parser.add_argument(
        "--exclude-last-months", type=int, default=0,
        help="åœ¨ IS é˜¶æ®µæ’é™¤æœ€å N ä¸ªæœˆçš„æ•°æ®ï¼ˆç•™ä½œ OOSï¼‰",
    )
    parser.add_argument(
        "--auto-test-top", type=int, default=0,
        help="è‡ªåŠ¨åœ¨ OOS æ•°æ®ä¸Šæµ‹è¯•æ’åå‰ N çš„ç»„åˆ",
    )
    parser.add_argument(
        "--skip-analysis", action="store_true",
        help="è·³è¿‡åˆ†æé˜¶æ®µ (ä»…å›æµ‹)",
    )
    parser.add_argument(
        "--analysis-only", action="store_true",
        help="ä»…åˆ†æå·²æœ‰ CSV ç»“æœ (ä¸è·‘å›æµ‹)",
    )
    parser.add_argument(
        "--use-groups", action="store_true",
        help="ä½¿ç”¨æ¨¡å‹åˆ†ç»„éå† (åŒç»„åªé€‰ä¸€ä¸ª)",
    )
    parser.add_argument(
        "--group-config", type=str, default="config/combo_groups.yaml",
        help="åˆ†ç»„é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config/combo_groups.yaml)",
    )
    # å¿«é€Ÿæ¨¡å¼ç‰¹æœ‰å‚æ•°
    parser.add_argument(
        "--batch-size", type=int, default=512,
        help="æ‰¹é‡å¤„ç†å¤§å° (é»˜è®¤: 512)",
    )
    parser.add_argument(
        "--use-gpu", action="store_true",
        help="å¼ºåˆ¶ä½¿ç”¨ GPU (CuPy)",
    )
    parser.add_argument(
        "--no-gpu", action="store_true",
        help="å¼ºåˆ¶ç¦ç”¨ GPU",
    )
    parser.add_argument(
        "--cost-rate", type=float, default=0.002,
        help="å•æ¬¡æ¢æ‰‹äº¤æ˜“è´¹ç”¨ç‡ (é»˜è®¤: 0.002 = åŒè¾¹ 0.2%%)",
    )
    args = parser.parse_args()

    # åˆå§‹åŒ–
    print("=" * 60)
    print("âš¡ Brute Force Fast - å‘é‡åŒ–å¿«é€Ÿæš´åŠ›ç©·ä¸¾å›æµ‹")
    print(f"å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    # GPU åˆå§‹åŒ–
    _init_gpu(force_gpu=args.use_gpu, force_no_gpu=args.no_gpu)

    init_qlib()

    # åŠ è½½é…ç½®
    train_records, model_config = load_config(args.record_file)
    anchor_date = train_records.get(
        "anchor_date", datetime.now().strftime("%Y-%m-%d")
    )
    top_k = model_config.get("TopK", 22)
    drop_n = model_config.get("DropN", 3)
    benchmark = model_config.get("benchmark", "SH000300")

    # è¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)

    # Stage 1: åŠ è½½é¢„æµ‹æ•°æ®
    norm_df, model_metrics = load_predictions(train_records)

    # åˆ’åˆ†æ•°æ®é›† (IS / OOS)
    is_norm_df, oos_norm_df = split_is_oos_by_args(norm_df, args)
    if is_norm_df.empty:
        print("é”™è¯¯: IS æœŸæ— æ•°æ®ï¼è¯·æ£€æŸ¥æ—¥æœŸå‚æ•°ã€‚")
        sys.exit(1)

    # Stage 2: ç›¸å…³æ€§åˆ†æ
    corr_matrix = correlation_analysis(is_norm_df, args.output_dir, anchor_date)

    if not args.analysis_only:
        # ç¡®å®šè°ƒä»“é¢‘ç‡ (å‘¨é¢‘=5å¤©, æ—¥é¢‘=1å¤©)
        rebalance_freq = 5 if args.freq == "week" else 1

        # åŠ è½½æ—¥é¢‘æ”¶ç›Šç‡çŸ©é˜µ (æ— è®º freq æ˜¯ä»€ä¹ˆéƒ½åŠ è½½æ—¥é¢‘ï¼Œå…¨é‡åŠ è½½)
        returns_wide, bench_returns, common_dates, instruments = load_returns_matrix(
            norm_df, freq=args.freq
        )

        # æ„å»º IS å¯¹é½çŸ©é˜µ
        is_dates = is_norm_df.index.get_level_values("datetime").unique().sort_values()
        is_common_dates = is_dates.intersection(returns_wide.index)
        
        scores_np, returns_np, model_names, date_index, inst_index = prepare_matrices(
            is_norm_df, returns_wide, is_common_dates
        )

        # å¯¹é½åŸºå‡†æ”¶ç›Š (IS)
        bench_returns_np = bench_returns.reindex(date_index).fillna(0).values.astype(np.float32)

        # Stage 3: å¿«é€Ÿå›æµ‹
        results_df = brute_force_fast_backtest(
            scores_np=scores_np,
            returns_np=returns_np,
            model_names=model_names,
            bench_returns_np=bench_returns_np,
            top_k=top_k,
            freq=args.freq,
            cost_rate=args.cost_rate,
            batch_size=args.batch_size,
            min_combo_size=args.min_combo_size,
            max_combo_size=args.max_combo_size,
            output_dir=args.output_dir,
            anchor_date=anchor_date,
            resume=args.resume,
            rebalance_freq=rebalance_freq,
            use_groups=args.use_groups,
            group_config=args.group_config,
        )
    else:
        # ç›´æ¥è¯»å–å·²æœ‰ç»“æœ
        import glob
        csv_path = os.path.join(
            args.output_dir, f"brute_force_fast_results_{anchor_date}.csv"
        )
        if not os.path.exists(csv_path):
            pattern = os.path.join(args.output_dir, "brute_force_fast_results_*.csv")
            files = sorted(glob.glob(pattern))
            if files:
                csv_path = files[-1]
                print(f"ä½¿ç”¨æœ€æ–°ç»“æœæ–‡ä»¶: {csv_path}")
            else:
                print(f"é”™è¯¯: æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶ ({pattern})")
                sys.exit(1)
        results_df = pd.read_csv(csv_path)
        print(f"\nå·²åŠ è½½ç°æœ‰ç»“æœ: {csv_path} ({len(results_df)} æ¡)")

    # Stage 4: åˆ†æ
    if not args.skip_analysis and not results_df.empty:
        analyze_results(
            results_df=results_df,
            corr_matrix=corr_matrix,
            norm_df=is_norm_df,
            train_records=train_records,
            output_dir=args.output_dir,
            anchor_date=anchor_date,
            top_n=args.top_n,
        )

    # Stage 5: OOS éªŒè¯
    if getattr(args, "auto_test_top", 0) > 0 and not results_df.empty:
        if oos_norm_df.empty:
            print("\nâš ï¸ æ— æ³•è¿›è¡Œ âš¡ å¿«é€Ÿ OOS éªŒè¯ï¼šæ—  OOS æ•°æ®ï¼è¯·é…åˆä½¿ç”¨ --exclude-last-years æˆ–ç±»ä¼¼å‚æ•°ã€‚")
        else:
            print(f"\n{'='*60}")
            print(f"Stage 5: âš¡ å¿«é€Ÿ Out-Of-Sample (OOS) éªŒè¯ (Top {args.auto_test_top})")
            print(f"{'='*60}")
            
            rebalance_freq = 5 if args.freq == "week" else 1
            if args.analysis_only:
                # è‹¥ä½¿ç”¨äº† analysis_onlyï¼Œéœ€è¦å•ç‹¬åŠ è½½ä¸€ä¸‹å…¨é‡æ”¶ç›ŠçŸ©é˜µ
                returns_wide, bench_returns, common_dates, instruments = load_returns_matrix(
                    norm_df, freq=args.freq
                )
                
            oos_dates = oos_norm_df.index.get_level_values("datetime").unique().sort_values()
            oos_common_dates = oos_dates.intersection(returns_wide.index)
            
            oos_scores_np, oos_returns_np, _, oos_date_index, _ = prepare_matrices(
                oos_norm_df, returns_wide, oos_common_dates
            )
            oos_bench_returns_np = bench_returns.reindex(oos_date_index).fillna(0).values.astype(np.float32)

            top_combos = results_df.head(args.auto_test_top)["models"].tolist()
            
            oos_returns_gpu = xp.asarray(oos_returns_np)
            oos_scores_gpu = {m: xp.asarray(v) for m, v in oos_scores_np.items()}
            
            oos_results = []
            for combo_str in tqdm(top_combos, desc="OOS Testing"):
                combo = combo_str.split(",")
                combo_score = sum(oos_scores_gpu[m] for m in combo) / len(combo)
                
                net_ret = _vectorized_topk_backtest_single(
                    combo_score, oos_returns_gpu, top_k, args.cost_rate, rebalance_freq,
                )
                metrics = compute_metrics(net_ret, oos_bench_returns_np, args.freq)
                metrics["models"] = combo_str
                metrics["n_models"] = len(combo)
                oos_results.append(metrics)
                
            if _USE_GPU:
                del oos_returns_gpu, oos_scores_gpu
                import cupy as cp
                cp.get_default_memory_pool().free_all_blocks()
                
            if oos_results:
                oos_df = pd.DataFrame(oos_results)
                oos_path = os.path.join(args.output_dir, f"oos_validation_{anchor_date}.csv")
                oos_df.to_csv(oos_path, index=False)
                print(f"OOS ç»“æœå·²ä¿å­˜: {oos_path}")
                
                print("\nâš¡ å¿«é€Ÿ OOS éªŒè¯ç»“æœ:")
                display_cols = ["models", "Ann_Ret", "Max_DD", "Ann_Excess", "Calmar"]
                fmt = {
                    "Ann_Ret": "{:.2%}".format,
                    "Max_DD": "{:.2%}".format,
                    "Ann_Excess": "{:.2%}".format,
                    "Calmar": "{:.2f}".format,
                }
                print(oos_df[display_cols].to_string(formatters=fmt))

    print(f"\n{'='*60}")
    print(f"å…¨éƒ¨å®Œæˆï¼ è€—æ—¶ç»“æŸäº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
