#!/usr/bin/env python
"""
Brute Force Ensemble - æš´åŠ›ç©·ä¸¾ç»„åˆå›æµ‹ + ç»“æœåˆ†æ

å°†æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹ç»“æœè¿›è¡Œæš´åŠ›ç»„åˆï¼Œå¯¹æ¯ä¸ªç»„åˆåšç­‰æƒèåˆ+å›æµ‹ï¼Œ
æœ€åå¯¹ç»“æœè¿›è¡Œå…¨é¢åˆ†æï¼ˆæ¨¡å‹å½’å› ã€ç›¸å…³æ€§ã€èšç±»ã€ä¼˜åŒ–æƒé‡ç­‰ï¼‰ã€‚

è¿è¡Œæ–¹å¼ï¼š
  cd QuantPits && python engine/scripts/brute_force_ensemble.py

å¸¸ç”¨å‘½ä»¤ï¼š
  # å¿«é€Ÿæµ‹è¯•ï¼ˆæœ€å¤š3ä¸ªæ¨¡å‹çš„ç»„åˆï¼‰
  python engine/scripts/brute_force_ensemble.py --max-combo-size 3

  # ä»…åˆ†æå·²æœ‰ç»“æœï¼ˆä¸é‡æ–°è·‘å›æµ‹ï¼‰
  python engine/scripts/brute_force_ensemble.py --analysis-only

  # å®Œæ•´ç©·ä¸¾ + åˆ†æ
  python engine/scripts/brute_force_ensemble.py

  # ä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­
  python engine/scripts/brute_force_ensemble.py --resume

  # åªè·‘å›æµ‹ã€è·³è¿‡åˆ†æ
  python engine/scripts/brute_force_ensemble.py --skip-analysis

  # ä½¿ç”¨æ¨¡å‹åˆ†ç»„ç©·ä¸¾ (æ¯ç»„åªé€‰ä¸€ä¸ª) â€” å¤§å¹…å‡å°‘ç»„åˆæ•°
  python engine/scripts/brute_force_ensemble.py --use-groups

  # æŒ‡å®šè‡ªå®šä¹‰åˆ†ç»„é…ç½®
  python engine/scripts/brute_force_ensemble.py --use-groups --group-config config/my_groups.yaml
"""

import os
import sys
import json
import gc
import signal
import itertools
import logging
import argparse
from datetime import datetime
from collections import Counter
from itertools import chain
from concurrent.futures import ThreadPoolExecutor, as_completed

import yaml

import pandas as pd
import numpy as np
from tqdm.auto import tqdm

# ---------------------------------------------------------------------------
# è·¯å¾„è®¾ç½®
# ---------------------------------------------------------------------------
import env

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = env.ROOT_DIR
os.chdir(ROOT_DIR)

# ---------------------------------------------------------------------------
# å¸¸é‡
# ---------------------------------------------------------------------------
BACKTEST_CONFIG = {
    "account": 100_000_000,
    "exchange_kwargs": {
        "freq": "day",
        "limit_threshold": 0.095,
        "deal_price": "close",
        "open_cost": 0.0005,
        "close_cost": 0.0015,
        "min_cost": 5,
    },
}

# ---------------------------------------------------------------------------
# å…¨å±€ä¸­æ–­æ ‡å¿— & ä¿¡å·å¤„ç†
# ---------------------------------------------------------------------------
_shutdown = False
_original_sigint = None
_original_sigterm = None


def _signal_handler(signum, frame):
    """æ”¶åˆ° SIGINT/SIGTERM åæ ‡è®°å®‰å…¨ä¸­æ–­"""
    global _shutdown
    if _shutdown:
        # ç¬¬äºŒæ¬¡ä¸­æ–­ â†’ å¼ºåˆ¶é€€å‡º
        print("\n\nâ›” å†æ¬¡æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œå¼ºåˆ¶é€€å‡º...")
        sys.exit(1)
    _shutdown = True
    sig_name = "SIGINT (Ctrl+C)" if signum == signal.SIGINT else "SIGTERM"
    print(f"\n\nâš ï¸  æ”¶åˆ° {sig_name}ï¼Œå°†åœ¨å½“å‰æ‰¹æ¬¡å®Œæˆåå®‰å…¨é€€å‡º...")
    print("   (å†æ¬¡æŒ‰ Ctrl+C å¼ºåˆ¶é€€å‡º)")


def _install_signal_handlers():
    """å®‰è£…ä¿¡å·å¤„ç†å™¨"""
    global _original_sigint, _original_sigterm
    _original_sigint = signal.getsignal(signal.SIGINT)
    _original_sigterm = signal.getsignal(signal.SIGTERM)
    signal.signal(signal.SIGINT, _signal_handler)
    signal.signal(signal.SIGTERM, _signal_handler)


def _restore_signal_handlers():
    """æ¢å¤åŸå§‹ä¿¡å·å¤„ç†å™¨"""
    if _original_sigint is not None:
        signal.signal(signal.SIGINT, _original_sigint)
    if _original_sigterm is not None:
        signal.signal(signal.SIGTERM, _original_sigterm)


# ============================================================================
# Stage 0: åˆå§‹åŒ– & é…ç½®åŠ è½½
# ============================================================================

def init_qlib():
    """åˆå§‹åŒ– Qlib"""
    import qlib
    from qlib.constant import REG_CN
    provider_uri = "~/.qlib/qlib_data/cn_data"
    qlib.init(provider_uri=provider_uri, region=REG_CN)


def load_config(record_file="latest_train_records.json"):
    """åŠ è½½è®­ç»ƒè®°å½•å’Œæ¨¡å‹é…ç½®"""
    with open(record_file, "r") as f:
        train_records = json.load(f)

    with open("config/model_config.json", "r") as f:
        model_config = json.load(f)

    return train_records, model_config


# ============================================================================
# Stage 1: åŠ è½½é¢„æµ‹æ•°æ®
# ============================================================================

def zscore_norm(series):
    """æŒ‰å¤© Z-Score å½’ä¸€åŒ– (å‡å‡å€¼ï¼Œé™¤æ ‡å‡†å·®)"""
    def _norm_func(x):
        std = x.std()
        if std == 0:
            return x - x.mean()
        return (x - x.mean()) / std
    return series.groupby(level="datetime", group_keys=False).apply(_norm_func)


def load_predictions(train_records):
    """
    ä» Qlib Recorder åŠ è½½æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹å€¼ï¼Œå½’ä¸€åŒ–åè¿”å›å®½è¡¨ã€‚

    Returns:
        norm_df: DataFrame, index=(datetime, instrument), columns=model_names
        model_metrics: dict, model_name -> ICIR
    """
    from qlib.workflow import R

    experiment_name = train_records["experiment_name"]
    models = train_records["models"]

    all_preds = []
    model_metrics = {}

    print(f"\n{'='*60}")
    print("Stage 1: åŠ è½½æ¨¡å‹é¢„æµ‹æ•°æ®")
    print(f"{'='*60}")
    print(f"Experiment: {experiment_name}")
    print(f"Models ({len(models)}): {list(models.keys())}")

    for model_name, record_id in models.items():
        try:
            recorder = R.get_recorder(
                recorder_id=record_id, experiment_name=experiment_name
            )

            # åŠ è½½é¢„æµ‹å€¼
            pred = recorder.load_object("pred.pkl")
            if isinstance(pred, pd.Series):
                pred = pred.to_frame("score")
            pred.columns = [model_name]
            all_preds.append(pred)

            # è¯»å– ICIR æŒ‡æ ‡
            raw_metrics = recorder.list_metrics()
            metric_val = 0.0
            for k, v in raw_metrics.items():
                if "ICIR" in k:
                    metric_val = v
                    break
            model_metrics[model_name] = metric_val

            print(f"  [{model_name}] OK. Preds={len(pred)}, ICIR={metric_val:.4f}")
        except Exception as e:
            print(f"  [{model_name}] FAILED: {e}")

    print(f"\næˆåŠŸåŠ è½½ {len(all_preds)}/{len(models)} ä¸ªæ¨¡å‹")

    if not all_preds:
        raise ValueError("æœªåŠ è½½åˆ°ä»»ä½•é¢„æµ‹æ•°æ®ï¼")

    # åˆå¹¶ & Z-Score å½’ä¸€åŒ–
    merged_df = pd.concat(all_preds, axis=1).dropna()
    print(f"åˆå¹¶åæ•°æ®ç»´åº¦: {merged_df.shape}")

    norm_df = pd.DataFrame(index=merged_df.index)
    for col in merged_df.columns:
        norm_df[col] = zscore_norm(merged_df[col])

    return norm_df, model_metrics


# ============================================================================
# Stage 2: ç›¸å…³æ€§åˆ†æ
# ============================================================================

def correlation_analysis(norm_df, output_dir, anchor_date):
    """è®¡ç®—å¹¶ä¿å­˜é¢„æµ‹å€¼ç›¸å…³æ€§çŸ©é˜µ"""
    print(f"\n{'='*60}")
    print("Stage 2: ç›¸å…³æ€§åˆ†æ")
    print(f"{'='*60}")

    corr_matrix = norm_df.corr()
    print("\n=== æ¨¡å‹é¢„æµ‹ç›¸å…³æ€§çŸ©é˜µ ===")
    print(corr_matrix.round(4))

    # ä¿å­˜
    corr_path = os.path.join(output_dir, f"correlation_matrix_{anchor_date}.csv")
    corr_matrix.to_csv(corr_path)
    print(f"\nç›¸å…³æ€§çŸ©é˜µå·²ä¿å­˜: {corr_path}")

    return corr_matrix


def split_is_oos_by_args(norm_df, args):
    """æ ¹æ®å‚æ•°å°† norm_df åˆ’åˆ†ä¸º IS (In-Sample) å’Œ OOS (Out-of-Sample)"""
    start_date = pd.to_datetime(args.start_date) if args.start_date else None
    
    dates = norm_df.index.get_level_values("datetime").unique().sort_values()
    max_date = dates.max()
    
    cutoff_date = max_date
    if args.exclude_last_years > 0:
        cutoff_date = cutoff_date - pd.DateOffset(years=args.exclude_last_years)
    if args.exclude_last_months > 0:
        cutoff_date = cutoff_date - pd.DateOffset(months=args.exclude_last_months)
        
    end_date = pd.to_datetime(args.end_date) if args.end_date else None
    if end_date and end_date < cutoff_date:
        cutoff_date = end_date
        
    is_mask = norm_df.index.get_level_values("datetime") <= cutoff_date
    if start_date:
        is_mask &= norm_df.index.get_level_values("datetime") >= start_date
        
    is_norm_df = norm_df[is_mask]
    
    # OOS æ˜¯æˆªæ­¢æ—¥ä¹‹åçš„æ•°æ®ï¼ˆå¦‚æœæœ‰æŒ‡å®š start_date/end_dateï¼Œæš‚ä¸é™åˆ¶ OOS çš„æœ«å°¾è·¨åº¦ï¼Œæˆ–åªä¿ç•™å‰©ä¸‹çš„ï¼‰
    oos_mask = norm_df.index.get_level_values("datetime") > cutoff_date
    oos_norm_df = norm_df[oos_mask]
    
    print(f"\n=== æ•°æ®é›†åˆ’åˆ† (In-Sample / Out-Of-Sample) ===")
    if not is_norm_df.empty:
        print(f"IS æœŸ  : {is_norm_df.index.get_level_values('datetime').min().date()} ~ {is_norm_df.index.get_level_values('datetime').max().date()} (å…± {len(is_norm_df.index.get_level_values('datetime').unique())} å¤©)")
    else:
        print("IS æœŸ  : æ— æ•°æ®")
        
    if not oos_norm_df.empty:
        print(f"OOS æœŸ : {oos_norm_df.index.get_level_values('datetime').min().date()} ~ {oos_norm_df.index.get_level_values('datetime').max().date()} (å…± {len(oos_norm_df.index.get_level_values('datetime').unique())} å¤©)")
    else:
        print("OOS æœŸ : æ— æ•°æ®")
        
    return is_norm_df, oos_norm_df


# ============================================================================
# Stage 2.5: æ¨¡å‹åˆ†ç»„ & ç»„åˆç”Ÿæˆ
# ============================================================================

def load_combo_groups(group_config_path, available_models):
    """
    åŠ è½½åˆ†ç»„é…ç½®ï¼ŒéªŒè¯æ¨¡å‹åï¼Œè¿”å›æœ‰æ•ˆåˆ†ç»„ã€‚

    Args:
        group_config_path: combo_groups.yaml è·¯å¾„
        available_models: å½“å‰åŠ è½½åˆ°çš„æ¨¡å‹åˆ—è¡¨ (norm_df.columns)

    Returns:
        groups: dict, group_name -> list of valid model names
    """
    with open(group_config_path, "r", encoding="utf-8") as f:
        cfg = yaml.safe_load(f)

    raw_groups = cfg.get("groups", {})
    if not raw_groups:
        raise ValueError(f"åˆ†ç»„é…ç½®ä¸ºç©º: {group_config_path}")

    available_set = set(available_models)
    groups = {}
    skipped_models = []

    for gname, models in raw_groups.items():
        valid = [m for m in models if m in available_set]
        invalid = [m for m in models if m not in available_set]
        if invalid:
            skipped_models.extend(invalid)
            print(f"  âš ï¸  ç»„ [{gname}] ä¸­ä»¥ä¸‹æ¨¡å‹ä¸å­˜åœ¨äºé¢„æµ‹æ•°æ®ä¸­ï¼Œå·²å¿½ç•¥: {invalid}")
        if valid:
            groups[gname] = valid
        else:
            print(f"  âš ï¸  ç»„ [{gname}] æ— æœ‰æ•ˆæ¨¡å‹ï¼Œå·²è·³è¿‡")

    if skipped_models:
        print(f"  å…±å¿½ç•¥ {len(skipped_models)} ä¸ªæ— æ•ˆæ¨¡å‹")

    # æ£€æŸ¥æœªåˆ†ç»„çš„æ¨¡å‹ (ä»…æ‰“å°æç¤ºï¼Œä¸è‡ªåŠ¨å‚ä¸)
    grouped_models = set()
    for models in groups.values():
        grouped_models.update(models)
    ungrouped = available_set - grouped_models
    if ungrouped:
        print(f"  â„¹ï¸  ä»¥ä¸‹æ¨¡å‹æœªåœ¨ä»»ä½•åˆ†ç»„ä¸­ï¼Œå°†è¢«æ’é™¤: {sorted(ungrouped)}")

    return groups


def generate_grouped_combinations(groups, min_combo_size=1, max_combo_size=0):
    """
    åŸºäºåˆ†ç»„ç”Ÿæˆç»„åˆï¼šä»æ‰€æœ‰ç»„çš„å­é›†ä¸­ï¼Œæ¯ç»„é€‰ä¸€ä¸ªæ¨¡å‹ï¼Œåšç¬›å¡å°”ç§¯ã€‚

    ä¸ºæ”¯æŒ min/max combo sizeï¼Œæˆ‘ä»¬æšä¸¾ç»„çš„å­é›†ï¼ˆé€‰å“ªäº›ç»„å‚ä¸ï¼‰ï¼Œ
    ç„¶åå¯¹å‚ä¸çš„ç»„åš itertools.productã€‚

    Args:
        groups: dict, group_name -> list of models
        min_combo_size: æœ€å°ç»„åˆå¤§å° (é€‰å‡ ä¸ªç»„)
        max_combo_size: æœ€å¤§ç»„åˆå¤§å° (0=å…¨éƒ¨ç»„)

    Returns:
        list of tuples, æ¯ä¸ª tuple æ˜¯ä¸€ä¸ªæ¨¡å‹ç»„åˆ
    """
    group_names = list(groups.keys())
    n_groups = len(group_names)
    max_size = max_combo_size if max_combo_size > 0 else n_groups
    max_size = min(max_size, n_groups)

    all_combinations = []

    # æšä¸¾é€‰å“ªäº›ç»„å‚ä¸ (é€‰ r ä¸ªç»„çš„ç»„åˆ)
    for r in range(min_combo_size, max_size + 1):
        for group_subset in itertools.combinations(group_names, r):
            # å¯¹é€‰ä¸­çš„ç»„åšç¬›å¡å°”ç§¯
            model_lists = [groups[g] for g in group_subset]
            for combo in itertools.product(*model_lists):
                all_combinations.append(combo)

    return all_combinations


# ============================================================================
# Stage 3: æš´åŠ›ç©·ä¸¾å›æµ‹
# ============================================================================

def extract_report_df(metrics):
    """ä»å›æµ‹ç»“æœä¸­æå– report DataFrame"""
    if isinstance(metrics, dict):
        val = list(metrics.values())[0]
        return val[0] if isinstance(val, tuple) else val
    elif isinstance(metrics, tuple):
        first = metrics[0]
        if isinstance(first, pd.DataFrame):
            return first
        elif isinstance(first, tuple) and len(first) >= 1:
            return first[0]
        return metrics
    return metrics


def run_single_backtest(
    combo_models, norm_df, top_k, drop_n, benchmark, freq,
    trade_exchange, bt_start, bt_end
):
    """å¯¹æŒ‡å®šçš„æ¨¡å‹ç»„åˆè¿›è¡Œå›æµ‹ï¼Œè¿”å›æŒ‡æ ‡å­—å…¸æˆ– None"""
    from qlib.backtest import backtest_loop
    from qlib.backtest.executor import SimulatorExecutor
    from qlib.backtest.utils import CommonInfrastructure
    from qlib.backtest.account import Account
    from qlib.contrib.strategy import TopkDropoutStrategy

    # 1. åˆæˆä¿¡å· (ç­‰æƒå‡å€¼ï¼Œå½’ä¸€åŒ–åçš„)
    combo_score = norm_df[list(combo_models)].mean(axis=1)

    # 2. å‡†å¤‡ç»„ä»¶
    # æ³¨æ„: Account å¿…é¡»æ¯æ¬¡æ–°å»ºï¼Œä¸èƒ½å¤ç”¨ (çŠ¶æ€ä¼šç´¯ç§¯)
    trade_account = Account(init_cash=BACKTEST_CONFIG["account"])
    
    # CommonInfrastructure ç»„åˆ: æ–° Account + å…±äº« Exchange
    common_infra = CommonInfrastructure(
        trade_account=trade_account,
        trade_exchange=trade_exchange
    )

    strategy = TopkDropoutStrategy(
        signal=combo_score, topk=top_k, n_drop=drop_n, only_tradable=True
    )
    # ç­–ç•¥éœ€è¦å…³è” infra
    strategy.reset_common_infra(common_infra)

    executor_obj = SimulatorExecutor(
        time_per_step=freq,
        generate_portfolio_metrics=True,
        verbose=False,
        common_infra=common_infra,
    )

    # 3. å›æµ‹
    try:
        # ä½¿ç”¨ backtest_loop ç›´æ¥è¿è¡Œï¼Œé¿å… backtest() å‡½æ•°å†…éƒ¨é‡å»º Exchange
        raw_portfolio_metrics, _ = backtest_loop(
            start_time=bt_start,
            end_time=bt_end,
            trade_strategy=strategy,
            trade_executor=executor_obj,
        )

        # 4. æå–ç»“æœ
        report = extract_report_df(raw_portfolio_metrics)

        initial_cash = BACKTEST_CONFIG["account"]
        final_nav = report.iloc[-1]["account"]
        ann_ret = report["return"].mean() * 52

        report["nav"] = report["account"]
        report["max_nav"] = report["nav"].cummax()
        report["drawdown"] = (report["nav"] - report["max_nav"]) / report["max_nav"]
        max_dd = report["drawdown"].min()

        total_ret = (final_nav / initial_cash) - 1
        bench_ret = (
            (report.iloc[-1]["bench"] - report.iloc[0]["bench"])
            / report.iloc[0]["bench"]
        )
        excess_ret = total_ret - bench_ret
        ann_excess = ann_ret - (report["bench"].mean() * 52)

        return {
            "models": ",".join(combo_models),
            "n_models": len(combo_models),
            "Ann_Ret": ann_ret,
            "Max_DD": max_dd,
            "Excess_Ret": excess_ret,
            "Ann_Excess": ann_excess,
            "Total_Ret": total_ret,
            "Final_NAV": final_nav,
            "Calmar": ann_ret / abs(max_dd) if max_dd != 0 else 0,
        }
    except Exception:
        # import traceback
        # traceback.print_exc()
        return None


def _append_results_to_csv(csv_path, results, write_header=False):
    """å°†ä¸€æ‰¹ç»“æœè¿½åŠ å†™å…¥ CSV æ–‡ä»¶"""
    if not results:
        return
    df = pd.DataFrame(results)
    df.to_csv(csv_path, mode="a", header=write_header, index=False)


def brute_force_backtest(
    norm_df, top_k, drop_n, benchmark, freq,
    min_combo_size, max_combo_size, output_dir, anchor_date, resume=False,
    n_jobs=4, use_groups=False, group_config=None,
    batch_size=50,
):
    """
    æš´åŠ›ç©·ä¸¾æ‰€æœ‰æ¨¡å‹ç»„åˆå¹¶å›æµ‹ã€‚

    æ”¯æŒ:
    - åˆ†æ‰¹æ‰§è¡Œ + å¢é‡ä¿å­˜ (é˜²æ­¢å´©æºƒä¸¢å¤±è¿›åº¦)
    - SIGINT/SIGTERM å®‰å…¨ä¸­æ–­
    - æ¨¡å‹åˆ†ç»„ç©·ä¸¾ (--use-groups)

    Returns:
        results_df: DataFrameï¼Œæ‰€æœ‰ç»„åˆçš„å›æµ‹ç»“æœ
    """
    global _shutdown
    _shutdown = False

    from qlib.backtest.exchange import Exchange

    print(f"\n{'='*60}")
    print("Stage 3: æš´åŠ›ç©·ä¸¾å›æµ‹ (Batched Threading + Checkpoint)")
    print(f"{'='*60}")

    model_candidates = list(norm_df.columns)

    # å‡†å¤‡å…±äº«çš„ Exchange å¯¹è±¡
    print("Initializing Shared Exchange...")
    bt_start = str(norm_df.index.get_level_values(0).min().date())
    bt_end = str(norm_df.index.get_level_values(0).max().date())
    all_codes = sorted(norm_df.index.get_level_values(1).unique().tolist())

    exchange_kwargs = BACKTEST_CONFIG["exchange_kwargs"].copy()
    exchange_freq = exchange_kwargs.pop("freq", "day")

    trade_exchange = Exchange(
        freq=exchange_freq,
        start_time=bt_start,
        end_time=bt_end,
        codes=all_codes,
        **exchange_kwargs
    )
    print(f"Shared Exchange Initialized. Period: {bt_start} ~ {bt_end}, Instruments: {len(all_codes)}")

    # â”€â”€ ç”Ÿæˆç»„åˆ â”€â”€
    if use_groups and group_config:
        print(f"\nğŸ“¦ åˆ†ç»„ç©·ä¸¾æ¨¡å¼ (é…ç½®: {group_config})")
        groups = load_combo_groups(group_config, model_candidates)
        print(f"æœ‰æ•ˆåˆ†ç»„ ({len(groups)}ä¸ª):")
        total_product = 1
        for gname, models in groups.items():
            print(f"  [{gname}] ({len(models)}ä¸ª): {models}")
            total_product *= len(models)

        all_combinations = generate_grouped_combinations(
            groups, min_combo_size, max_combo_size
        )
        print(f"\nåˆ†ç»„ç¬›å¡å°”ç§¯ç»„åˆæ•°: {len(all_combinations)}")
    else:
        max_size = max_combo_size if max_combo_size > 0 else len(model_candidates)
        max_size = min(max_size, len(model_candidates))
        print(f"å¾…ç©·ä¸¾æ¨¡å‹ ({len(model_candidates)}ä¸ª): {model_candidates}")
        print(f"ç»„åˆå¤§å°èŒƒå›´: {min_combo_size} ~ {max_size}")

        all_combinations = []
        for r in range(min_combo_size, max_size + 1):
            all_combinations.extend(itertools.combinations(model_candidates, r))

    print(f"æ€»ç»„åˆæ•°: {len(all_combinations)}")
    print(f"å›æµ‹é¢‘ç‡: {freq}, TopK={top_k}, DropN={drop_n}")
    print(f"å¹¶å‘çº¿ç¨‹æ•°: {n_jobs}, æ‰¹æ¬¡å¤§å°: {batch_size}")

    # â”€â”€ Resume: åŠ è½½å·²æœ‰ç»“æœ â”€â”€
    csv_path = os.path.join(output_dir, f"brute_force_results_{anchor_date}.csv")
    done_combos = set()

    if resume and os.path.exists(csv_path):
        existing_df = pd.read_csv(csv_path)
        done_combos = set(existing_df["models"].tolist())
        print(f"Resume æ¨¡å¼: å·²æœ‰ {len(done_combos)} ä¸ªç»„åˆï¼Œè·³è¿‡")

    # è¿‡æ»¤å·²å®Œæˆçš„ç»„åˆ
    pending = [
        c for c in all_combinations if ",".join(c) not in done_combos
    ]
    print(f"å¾…å›æµ‹ç»„åˆæ•°: {len(pending)}")

    if not pending:
        print("æ‰€æœ‰ç»„åˆå·²å®Œæˆï¼")
        if os.path.exists(csv_path):
            results_df = pd.read_csv(csv_path)
        else:
            results_df = pd.DataFrame()
    else:
        # å¦‚æœä¸æ˜¯ resumeï¼Œå…ˆå†™ä¸€ä¸ªç©ºçš„å¸¦ header çš„ CSV
        need_header = not (resume and os.path.exists(csv_path))
        if need_header:
            # å†™ header
            header_cols = [
                "models", "n_models", "Ann_Ret", "Max_DD",
                "Excess_Ret", "Ann_Excess", "Total_Ret", "Final_NAV", "Calmar"
            ]
            pd.DataFrame(columns=header_cols).to_csv(csv_path, index=False)

        # ä¸´æ—¶é™é»˜ Qlib æ—¥å¿—
        qlib_log = logging.getLogger("qlib")
        original_level = qlib_log.level
        qlib_log.setLevel(logging.WARNING)

        # å®‰è£…ä¿¡å·å¤„ç†å™¨
        _install_signal_handlers()

        completed_count = len(done_combos)
        total_count = len(all_combinations)
        failed_count = 0

        # â”€â”€ åˆ†æ‰¹å¤„ç† â”€â”€
        pbar = tqdm(
            total=len(pending),
            desc=f"Brute Force (Threads={n_jobs})",
            unit="combo",
        )

        try:
            for batch_start in range(0, len(pending), batch_size):
                if _shutdown:
                    break

                batch = pending[batch_start : batch_start + batch_size]
                batch_results = []

                # ä½¿ç”¨ ThreadPoolExecutor å¤„ç†å½“å‰æ‰¹æ¬¡
                with ThreadPoolExecutor(max_workers=n_jobs) as executor:
                    future_to_combo = {
                        executor.submit(
                            run_single_backtest,
                            combo, norm_df, top_k, drop_n, benchmark, freq,
                            trade_exchange, bt_start, bt_end
                        ): combo
                        for combo in batch
                    }

                    for future in as_completed(future_to_combo):
                        if _shutdown:
                            # æ”¶åˆ°ä¸­æ–­ï¼Œä¸å†ç­‰å¾…å…¶ä»– future
                            # ä½†å·²æäº¤çš„ä¼šç»§ç»­å®Œæˆ (ThreadPoolExecutor çš„è¡Œä¸º)
                            pass
                        try:
                            res = future.result()
                            if res:
                                batch_results.append(res)
                                completed_count += 1
                            else:
                                failed_count += 1
                        except Exception:
                            failed_count += 1
                        pbar.update(1)

                # æ‰¹æ¬¡å®Œæˆ â†’ å¢é‡å†™å…¥ CSV
                if batch_results:
                    _append_results_to_csv(csv_path, batch_results, write_header=False)

                # é‡Šæ”¾å†…å­˜
                del batch_results
                gc.collect()

                if _shutdown:
                    break

        finally:
            pbar.close()
            _restore_signal_handlers()
            qlib_log.setLevel(original_level)

        # æ‰“å°å®Œæˆ/ä¸­æ–­çŠ¶æ€
        if _shutdown:
            print(f"\nâš ï¸  å·²å®‰å…¨ä¸­æ–­ï¼")
            print(f"   å·²å®Œæˆ: {completed_count}/{total_count} ç»„åˆ")
            print(f"   å¤±è´¥: {failed_count} ä¸ª")
            print(f"   ç»“æœå·²ä¿å­˜è‡³: {csv_path}")
            print(f"   ä½¿ç”¨ --resume ç»§ç»­æœªå®Œæˆçš„ç»„åˆ")
        else:
            print(f"\nâœ… å›æµ‹å…¨éƒ¨å®Œæˆï¼")
            print(f"   æœ‰æ•ˆ: {completed_count - len(done_combos)}, å¤±è´¥: {failed_count}")

        # è¯»å–å®Œæ•´ç»“æœ (åŒ…æ‹¬ resume çš„)
        results_df = pd.read_csv(csv_path)

    # æ’åºå¹¶é‡æ–°ä¿å­˜
    if not results_df.empty:
        results_df = results_df.sort_values(
            by="Ann_Excess", ascending=False
        ).reset_index(drop=True)
        results_df.to_csv(csv_path, index=False)
        print(f"ç»“æœå·²æ’åºä¿å­˜: {csv_path} ({len(results_df)} æ¡)")
    else:
        print("è­¦å‘Š: æ— æœ‰æ•ˆå›æµ‹ç»“æœ")

    return results_df


# ============================================================================
# Stage 4: ç»“æœåˆ†æ
# ============================================================================

def analyze_results(
    results_df, corr_matrix, norm_df, train_records, output_dir, anchor_date, top_n=50,
):
    """å¯¹æš´åŠ›ç©·ä¸¾ç»“æœè¿›è¡Œå…¨é¢åˆ†æ"""
    import matplotlib
    matplotlib.use("Agg")
    import matplotlib.pyplot as plt
    import seaborn as sns

    print(f"\n{'='*60}")
    print("Stage 4: ç»“æœåˆ†æ")
    print(f"{'='*60}")

    if results_df.empty:
        print("æ— æ•°æ®å¯åˆ†æï¼")
        return

    # é¢„å¤„ç†
    df = results_df.copy()
    df["model_list"] = df["models"].apply(lambda x: x.split(","))
    df["is_single"] = df["n_models"] == 1

    report_lines = []  # æ”¶é›†æŠ¥å‘Šæ–‡æœ¬

    # -----------------------------------------------------------------------
    # 4.1 Top ç»„åˆå±•ç¤º
    # -----------------------------------------------------------------------
    display_cols = ["models", "n_models", "Ann_Ret", "Max_DD", "Ann_Excess", "Calmar"]
    fmt = {
        "Ann_Ret": "{:.2%}".format,
        "Max_DD": "{:.2%}".format,
        "Ann_Excess": "{:.2%}".format,
        "Calmar": "{:.2f}".format,
    }

    print("\nğŸ† === ç»¼åˆè¡¨ç°æœ€ä½³ Top 20 (æŒ‰å¹´åŒ–è¶…é¢) ===")
    top20_str = df[display_cols].head(20).to_string(formatters=fmt)
    print(top20_str)
    report_lines.append("=== Top 20 (æŒ‰å¹´åŒ–è¶…é¢) ===\n" + top20_str)

    robust_df = df[df["Ann_Ret"] > 0.10].sort_values(by="Max_DD", ascending=False)
    if not robust_df.empty:
        print("\nğŸ›¡ï¸ === æœ€ç¨³å¥ç»„åˆ Top 10 (å¹´åŒ–>10%, æŒ‰å›æ’¤æ’åº) ===")
        robust_str = robust_df[display_cols].head(10).to_string(formatters=fmt)
        print(robust_str)
        report_lines.append("\n=== æœ€ç¨³å¥ç»„åˆ Top 10 ===\n" + robust_str)

    # -----------------------------------------------------------------------
    # 4.2 æ¨¡å‹å½’å› åˆ†æ (Model Attribution)
    # -----------------------------------------------------------------------
    print(f"\nğŸ“Š === æ¨¡å‹å½’å› åˆ†æ (Top/Bottom {top_n}) ===")

    top_combinations = df.sort_values("Calmar", ascending=False).head(top_n)
    bottom_combinations = df.sort_values("Calmar", ascending=True).head(top_n)

    def get_model_counts(series_of_lists):
        all_models = list(chain.from_iterable(series_of_lists))
        return pd.Series(Counter(all_models)).sort_values(ascending=False)

    top_counts = get_model_counts(top_combinations["model_list"])
    bottom_counts = get_model_counts(bottom_combinations["model_list"])

    attribution = pd.DataFrame(
        {"Top_Count": top_counts, "Bottom_Count": bottom_counts}
    ).fillna(0)
    attribution["Net_Score"] = attribution["Top_Count"] - attribution["Bottom_Count"]
    attribution = attribution.sort_values("Net_Score", ascending=False)

    print(attribution)
    report_lines.append("\n=== æ¨¡å‹å½’å›  (Net Score) ===\n" + attribution.to_string())

    attr_path = os.path.join(output_dir, f"model_attribution_{anchor_date}.csv")
    attribution.to_csv(attr_path)
    print(f"å½’å› è¡¨å·²ä¿å­˜: {attr_path}")

    # å½’å› æ¡å½¢å›¾
    try:
        fig, ax = plt.subplots(figsize=(14, 6))
        x = np.arange(len(attribution))
        width = 0.35
        ax.bar(
            x - width / 2, attribution["Top_Count"], width,
            label=f"In Top {top_n}", color="forestgreen", alpha=0.7,
        )
        ax.bar(
            x + width / 2, attribution["Bottom_Count"], width,
            label=f"In Bottom {top_n}", color="firebrick", alpha=0.7,
        )
        ax.set_xticks(x)
        ax.set_xticklabels(attribution.index, rotation=45, ha="right")
        ax.set_ylabel("Frequency")
        ax.set_title(
            f"Model Importance Analysis (Top/Bottom {top_n} by Calmar)"
        )
        ax.legend()
        plt.tight_layout()
        attr_fig_path = os.path.join(
            output_dir, f"model_attribution_{anchor_date}.png"
        )
        plt.savefig(attr_fig_path, dpi=150)
        plt.close()
        print(f"å½’å› å›¾å·²ä¿å­˜: {attr_fig_path}")
    except Exception as e:
        print(f"å½’å› å›¾ç»˜åˆ¶å¤±è´¥: {e}")

    # -----------------------------------------------------------------------
    # 4.3 ç›¸å…³æ€§ vs ç»©æ•ˆåˆ†æ
    # -----------------------------------------------------------------------
    print("\nğŸ”— === ç›¸å…³æ€§ vs ç»©æ•ˆåˆ†æ ===")

    # æå–å•æ¨¡å‹è¡¨ç°
    single_model_perf = (
        df[df["n_models"] == 1].set_index("models")["Ann_Excess"].to_dict()
    )

    # ä½¿ç”¨åŸºäº unique ç»„åˆçš„é¢„å…ˆè®¡ç®—ï¼Œé¿å…ç™¾ä¸‡è¡Œçš„ row-by-row pd.apply
    unique_combos = df["models"].unique()
    combo_to_metrics = {}

    for combo_str in unique_combos:
        models_list = combo_str.split(",")
        n = len(models_list)

        # ç»„åˆå†…éƒ¨å¹³å‡ç›¸å…³æ€§
        if n < 2:
            avg_corr = 1.0
        else:
            try:
                sub = corr_matrix.loc[models_list, models_list].values
                upper_tri = sub[np.triu_indices(n, k=1)]
                avg_corr = np.mean(upper_tri) if len(upper_tri) > 0 else 1.0
            except KeyError:
                avg_corr = np.nan

        # å¤šæ ·æ€§çº¢åˆ©
        avg_individual_ret = np.mean(
            [single_model_perf.get(m, np.nan) for m in models_list]
        )
        combo_to_metrics[combo_str] = (avg_corr, avg_individual_ret)

    # æ˜ å°„å› DataFrame
    metrics_df = pd.DataFrame.from_dict(
        combo_to_metrics, orient="index", columns=["avg_corr", "avg_ind"]
    )
    
    # å°†æŒ‡æ ‡ merge è¿›åŸè¡¨
    df = df.merge(metrics_df, left_on="models", right_index=True, how="left")
    df["diversity_bonus"] = df["Ann_Excess"] - df["avg_ind"]
    df = df.drop(columns=["avg_ind"])

    # æ‰¾é»„é‡‘ç»„åˆ
    golden = df[
        (df["avg_corr"] < 0.3) & (df["Calmar"] > df["Calmar"].quantile(0.9))
    ]
    if not golden.empty:
        print(
            f"å‘ç° {len(golden)} ä¸ª'é»„é‡‘ç»„åˆ'ï¼šå†…éƒ¨ç›¸å…³æ€§ < 0.3 ä¸” Calmar å‰ 10%"
        )
        print(f"å…¸å‹ä»£è¡¨: {golden.iloc[0]['models']}")
        report_lines.append(
            f"\n=== é»„é‡‘ç»„åˆ ({len(golden)} ä¸ª) ===\n"
            + golden[display_cols + ["avg_corr"]].head(5).to_string(formatters=fmt)
        )
    else:
        print("æœªå‘ç°æ˜¾è‘—çš„'ä½ç›¸å…³æ€§-é«˜æ”¶ç›Š'ç»„åˆ")
        report_lines.append("\n=== é»„é‡‘ç»„åˆ: æœªå‘ç° ===")

    # ç›¸å…³æ€§ vs Calmar æ•£ç‚¹å›¾
    try:
        multi_df = df[df["n_models"] > 1].dropna(subset=["avg_corr"])
        if not multi_df.empty:
            # é˜²å†…å­˜æº¢å‡ºï¼šå¦‚æœç»„åˆè¶…è¿‡ 50,000ï¼ŒéšæœºæŠ½æ · 50,000 è¿›è¡Œç»˜å›¾
            MAX_PLOT_POINTS = 50000
            if len(multi_df) > MAX_PLOT_POINTS:
                print(f"æ•°æ®é‡è¿‡å¤§ ({len(multi_df)})ï¼ŒéšæœºæŠ½æ · {MAX_PLOT_POINTS} ä¸ªç‚¹è¿›è¡Œç»˜å›¾")
                plot_df = multi_df.sample(n=MAX_PLOT_POINTS, random_state=42)
            else:
                plot_df = multi_df

            fig, axes = plt.subplots(1, 2, figsize=(18, 8))

            # å›¾1: é£é™©-æ”¶ç›Šå…¨æ™¯å›¾
            scatter = axes[0].scatter(
                plot_df["Max_DD"].abs(), plot_df["Ann_Excess"],
                c=plot_df["n_models"], cmap="viridis", alpha=0.6,
                s=plot_df["n_models"] * 10 + 20,
            )
            singles = df[df["n_models"] == 1]
            axes[0].scatter(
                singles["Max_DD"].abs(), singles["Ann_Excess"],
                color="red", marker="x", s=100, label="Single Model",
            )
            axes[0].set_xlabel("Max Drawdown (Absolute)")
            axes[0].set_ylabel("Ann Excess Return")
            axes[0].set_title("Risk vs Return")
            axes[0].legend()
            plt.colorbar(scatter, ax=axes[0], label="# Models")

            # å›¾2: ç›¸å…³æ€§ vs Calmar
            sns.scatterplot(
                x="avg_corr", y="Calmar", hue="n_models",
                palette="viridis", data=plot_df, ax=axes[1], alpha=0.7,
            )
            sns.regplot(
                x="avg_corr", y="Calmar", data=plot_df,
                scatter=False, ax=axes[1], color="red",
                line_kws={"linestyle": "--"},
            )
            axes[1].set_title("Correlation vs Calmar")
            axes[1].set_xlabel("Avg Intra-Ensemble Correlation")

            plt.tight_layout()
            scatter_path = os.path.join(
                output_dir, f"risk_return_scatter_{anchor_date}.png"
            )
            plt.savefig(scatter_path, dpi=150)
            plt.close()
            print(f"æ•£ç‚¹å›¾å·²ä¿å­˜: {scatter_path}")
    except Exception as e:
        print(f"æ•£ç‚¹å›¾ç»˜åˆ¶å¤±è´¥: {e}")

    # æ¨¡å‹æ•°é‡åˆ†ç»„ç»Ÿè®¡
    group_stats = df.groupby("n_models")[["Ann_Excess", "Calmar"]].agg(
        ["median", "mean", "max"]
    )
    print("\n=== æŒ‰æ¨¡å‹æ•°é‡åˆ†ç»„ç»Ÿè®¡ ===")
    print(group_stats.round(4))
    report_lines.append(
        "\n=== æŒ‰æ¨¡å‹æ•°é‡åˆ†ç»„ç»Ÿè®¡ ===\n" + group_stats.round(4).to_string()
    )

    # -----------------------------------------------------------------------
    # 4.4 Cluster Dendrogram (åŸºäºå›æµ‹æŠ¥å‘Šçš„è¶…é¢æ”¶ç›Š)
    # -----------------------------------------------------------------------
    print("\nğŸŒ³ === å±‚æ¬¡èšç±»åˆ†æ ===")
    try:
        from qlib.workflow import R
        from scipy.cluster.hierarchy import dendrogram, linkage

        experiment_name = train_records["experiment_name"]
        models = train_records["models"]

        returns_dict = {}
        excess_dict = {}

        for model_name, record_id in models.items():
            try:
                recorder = R.get_recorder(
                    recorder_id=record_id, experiment_name=experiment_name
                )
                report = recorder.load_object(
                    "portfolio_analysis/report_normal_1week.pkl"
                )
                returns_dict[model_name] = report["return"]
                if "bench" in report.columns:
                    excess_dict[model_name] = report["return"] - report["bench"]
            except Exception as e:
                print(f"  [è·³è¿‡] {model_name}: {e}")

        if excess_dict:
            all_excess = pd.DataFrame(excess_dict).dropna()

            if len(all_excess.columns) >= 2:
                corr_excess = all_excess.corr()
                linked = linkage(corr_excess, "ward")

                fig, ax = plt.subplots(figsize=(12, 7))
                dendrogram(
                    linked, orientation="top", labels=corr_excess.columns.tolist(),
                    distance_sort="descending", show_leaf_counts=True, ax=ax,
                )
                ax.set_title("Model Alpha Cluster Dendrogram")
                ax.set_ylabel("Euclidean Distance (Dissimilarity)")
                plt.xticks(rotation=45, ha="right")
                plt.tight_layout()

                dendro_path = os.path.join(
                    output_dir, f"cluster_dendrogram_{anchor_date}.png"
                )
                plt.savefig(dendro_path, dpi=150)
                plt.close()
                print(f"èšç±»å›¾å·²ä¿å­˜: {dendro_path}")
            else:
                print("æ¨¡å‹æ•°é‡ä¸è¶³ï¼Œè·³è¿‡èšç±»")
        else:
            print("æ— è¶…é¢æ”¶ç›Šæ•°æ®ï¼Œè·³è¿‡èšç±»")
    except Exception as e:
        print(f"èšç±»åˆ†æå¤±è´¥: {e}")

    # -----------------------------------------------------------------------
    # 4.5 Portfolio Optimization (Top 10 å•æ¨¡å‹)
    # -----------------------------------------------------------------------
    print("\nğŸ“ === ä¼˜åŒ–æƒé‡åˆ†æ ===")
    try:
        from scipy.optimize import minimize

        if "all_excess" not in dir() or all_excess is None or all_excess.empty:
            # å°è¯•ä½¿ç”¨ returns_dict
            if returns_dict:
                all_returns_opt = pd.DataFrame(returns_dict).dropna()
            else:
                raise ValueError("æ— æ”¶ç›Šç‡æ•°æ®")
        else:
            all_returns_opt = pd.DataFrame(returns_dict).dropna()

        # é€‰å– Top 10 å•æ¨¡å‹
        top_singles = (
            df[df["n_models"] == 1]
            .sort_values("Calmar", ascending=False)
            .head(10)["models"]
            .tolist()
        )
        valid_models = [m for m in top_singles if m in all_returns_opt.columns]

        if len(valid_models) >= 2:
            subset = all_returns_opt[valid_models]
            mu = subset.mean() * 252
            cov = subset.cov() * 252
            num = len(valid_models)
            init_guess = [1.0 / num] * num
            constraints = {"type": "eq", "fun": lambda x: np.sum(x) - 1}
            bounds = tuple((0.0, 1.0) for _ in range(num))

            # Max Sharpe
            def neg_sharpe(w, mu, cov):
                ret = np.dot(w, mu)
                vol = np.sqrt(np.dot(w.T, np.dot(cov, w)))
                return -(ret / (vol + 1e-9))

            opt_sharpe = minimize(
                neg_sharpe, init_guess, args=(mu, cov),
                method="SLSQP", bounds=bounds, constraints=constraints,
            )

            # Risk Parity
            def risk_parity_obj(w, cov):
                w = np.array(w)
                port_vol = np.sqrt(np.dot(w.T, np.dot(cov, w)))
                mrc = np.dot(cov, w) / (port_vol + 1e-9)
                rc = w * mrc
                target = port_vol / len(w)
                return np.sum((rc - target) ** 2)

            opt_rp = minimize(
                risk_parity_obj, init_guess, args=(cov,),
                method="SLSQP", bounds=bounds, constraints=constraints,
            )

            weights_df = pd.DataFrame(
                {
                    "Equal_Weight": init_guess,
                    "Max_Sharpe": opt_sharpe.x,
                    "Risk_Parity": opt_rp.x,
                },
                index=valid_models,
            )

            print("\n=== æ™ºèƒ½ä¼˜åŒ–æƒé‡å¯¹æ¯” ===")
            print(weights_df.round(4))
            report_lines.append(
                "\n=== ä¼˜åŒ–æƒé‡å¯¹æ¯” ===\n" + weights_df.round(4).to_string()
            )

            opt_path = os.path.join(
                output_dir, f"optimization_weights_{anchor_date}.csv"
            )
            weights_df.to_csv(opt_path)
            print(f"ä¼˜åŒ–æƒé‡å·²ä¿å­˜: {opt_path}")

            # ç®€å•å›æµ‹å¯¹æ¯”
            def calc_stats(ret_series, name):
                ann_ret = ret_series.mean() * 252
                ann_vol = ret_series.std() * np.sqrt(252)
                sharpe = ann_ret / (ann_vol + 1e-9)
                return f"{name}: Sharpe={sharpe:.2f}, Ann Ret={ann_ret:.2%}, Vol={ann_vol:.2%}"

            ew_ret = subset.mean(axis=1)
            ms_ret = subset.dot(opt_sharpe.x)
            rp_ret = subset.dot(opt_rp.x)

            print("\nç»©æ•ˆæ€»ç»“:")
            stats_lines = [
                calc_stats(ew_ret, "Equal Weight"),
                calc_stats(ms_ret, "Max Sharpe  "),
                calc_stats(rp_ret, "Risk Parity "),
            ]
            for line in stats_lines:
                print(f"  {line}")
            report_lines.append(
                "\n=== ä¼˜åŒ–ç»©æ•ˆ ===\n" + "\n".join(stats_lines)
            )

            # å‡€å€¼æ›²çº¿
            try:
                fig, ax = plt.subplots(figsize=(14, 7))
                ax.plot(
                    (1 + ew_ret).cumprod(), label="Equal Weight",
                    linestyle="--", color="black",
                )
                ax.plot(
                    (1 + ms_ret).cumprod(), label="Max Sharpe", color="red",
                )
                ax.plot(
                    (1 + rp_ret).cumprod(), label="Risk Parity", color="green",
                )
                ax.set_title("Brute Force EW vs Mathematical Optimization")
                ax.legend()
                ax.grid(True, alpha=0.3)
                plt.tight_layout()

                opt_fig_path = os.path.join(
                    output_dir, f"optimization_equity_{anchor_date}.png"
                )
                plt.savefig(opt_fig_path, dpi=150)
                plt.close()
                print(f"å‡€å€¼æ›²çº¿å·²ä¿å­˜: {opt_fig_path}")
            except Exception as e:
                print(f"å‡€å€¼å›¾ç»˜åˆ¶å¤±è´¥: {e}")

        else:
            print("æœ‰æ•ˆæ¨¡å‹ä¸è¶³ 2 ä¸ªï¼Œè·³è¿‡ä¼˜åŒ–")
    except Exception as e:
        print(f"ä¼˜åŒ–åˆ†æå¤±è´¥: {e}")

    # -----------------------------------------------------------------------
    # 4.6 ç»¼åˆæŠ¥å‘Š
    # -----------------------------------------------------------------------
    best_combo = df.iloc[0]
    best_diversity_idx = df["diversity_bonus"].idxmax()
    best_diversity = df.loc[best_diversity_idx] if pd.notna(best_diversity_idx) else None

    summary = []
    summary.append("=" * 60)
    summary.append("è‡ªåŠ¨åˆ†ææŠ¥å‘Šæ‘˜è¦")
    summary.append("=" * 60)

    summary.append(f"\n1. æœ€ä½³ç»„åˆ (å¹´åŒ–è¶…é¢):")
    summary.append(f"   æ¨¡å‹: {best_combo['models']}")
    summary.append(f"   æ¨¡å‹æ•°: {best_combo['n_models']}")
    summary.append(f"   å¹´åŒ–æ”¶ç›Š: {best_combo['Ann_Ret']:.2%}")
    summary.append(f"   å¹´åŒ–è¶…é¢: {best_combo['Ann_Excess']:.2%}")
    summary.append(f"   æœ€å¤§å›æ’¤: {best_combo['Max_DD']:.2%}")
    summary.append(f"   Calmar: {best_combo['Calmar']:.2f}")

    if "avg_corr" in best_combo.index and pd.notna(best_combo.get("avg_corr")):
        summary.append(f"   å†…éƒ¨ç›¸å…³æ€§: {best_combo['avg_corr']:.4f}")

    if best_diversity is not None and pd.notna(best_diversity.get("diversity_bonus")):
        summary.append(f"\n2. æœ€å¤§å¤šæ ·æ€§çº¢åˆ©ç»„åˆ:")
        summary.append(f"   æ¨¡å‹: {best_diversity['models']}")
        summary.append(f"   Diversity Bonus: {best_diversity['diversity_bonus']:.4%}")

    summary.append(f"\n3. å»ºè®®ä¿ç•™çš„æ ¸å¿ƒæ¨¡å‹ (MVP):")
    summary.append(f"   {attribution.index[:3].tolist()}")
    summary.append("=" * 60)

    summary_text = "\n".join(summary)
    print(f"\n{summary_text}")

    # å†™å…¥æŠ¥å‘Šæ–‡ä»¶
    report_path = os.path.join(output_dir, f"analysis_report_{anchor_date}.txt")
    full_report = summary_text + "\n\n" + "\n".join(report_lines)
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(full_report)
    print(f"\nå®Œæ•´æŠ¥å‘Šå·²ä¿å­˜: {report_path}")


# ============================================================================
# Main
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="æš´åŠ›ç©·ä¸¾æ¨¡å‹ç»„åˆå›æµ‹ + ç»“æœåˆ†æ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¿«é€Ÿæµ‹è¯• (æœ€å¤š 3 ä¸ªæ¨¡å‹)
  python engine/scripts/brute_force_ensemble.py --max-combo-size 3

  # ä»…åˆ†æå·²æœ‰ç»“æœ
  python engine/scripts/brute_force_ensemble.py --analysis-only

  # å®Œæ•´ç©·ä¸¾ + åˆ†æ
  python engine/scripts/brute_force_ensemble.py

  # ä»ä¸­æ–­å¤„ç»§ç»­
  python engine/scripts/brute_force_ensemble.py --resume
        """,
    )
    parser.add_argument(
        "--record-file", type=str, default="latest_train_records.json",
        help="è®­ç»ƒè®°å½•æ–‡ä»¶è·¯å¾„ (é»˜è®¤: latest_train_records.json)",
    )
    parser.add_argument(
        "--max-combo-size", type=int, default=0,
        help="æœ€å¤§ç»„åˆå¤§å° (0=å…¨éƒ¨, é»˜è®¤: 0)",
    )
    parser.add_argument(
        "--min-combo-size", type=int, default=1,
        help="æœ€å°ç»„åˆå¤§å° (é»˜è®¤: 1)",
    )
    parser.add_argument(
        "--freq", type=str, default="week", choices=["day", "week"],
        help="å›æµ‹äº¤æ˜“é¢‘ç‡ (é»˜è®¤: week)",
    )
    parser.add_argument(
        "--top-n", type=int, default=50,
        help="åˆ†ææ—¶ Top/Bottom N (é»˜è®¤: 50)",
    )
    parser.add_argument(
        "--output-dir", type=str, default="output/brute_force",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: output/brute_force)",
    )
    parser.add_argument(
        "--start-date", type=str, default=None,
        help="å›æµ‹å¼€å§‹æ—¥æœŸ YYYY-MM-DD",
    )
    parser.add_argument(
        "--end-date", type=str, default=None,
        help="å›æµ‹ç»“æŸæ—¥æœŸ YYYY-MM-DD",
    )
    parser.add_argument(
        "--exclude-last-years", type=int, default=0,
        help="åœ¨ IS é˜¶æ®µæ’é™¤æœ€å N å¹´çš„æ•°æ®ï¼ˆç•™ä½œ OOSï¼‰",
    )
    parser.add_argument(
        "--exclude-last-months", type=int, default=0,
        help="åœ¨ IS é˜¶æ®µæ’é™¤æœ€å N ä¸ªæœˆçš„æ•°æ®ï¼ˆç•™ä½œ OOSï¼‰",
    )
    parser.add_argument(
        "--auto-test-top", type=int, default=0,
        help="è‡ªåŠ¨åœ¨ OOS æ•°æ®ä¸Šæµ‹è¯•æ’åå‰ N çš„ç»„åˆ",
    )
    parser.add_argument(
        "--resume", action="store_true",
        help="ä»å·²æœ‰ CSV ç»§ç»­ (è·³è¿‡å·²å®Œæˆçš„ç»„åˆ)",
    )
    parser.add_argument(
        "--skip-analysis", action="store_true",
        help="è·³è¿‡åˆ†æé˜¶æ®µ (ä»…å›æµ‹)",
    )
    parser.add_argument(
        "--analysis-only", action="store_true",
        help="ä»…åˆ†æå·²æœ‰ CSV ç»“æœ (ä¸è·‘å›æµ‹)",
    )
    parser.add_argument(
        "--n-jobs", type=int, default=4,
        help="å¹¶å‘å›æµ‹çº¿ç¨‹æ•° (é»˜è®¤: 4)",
    )
    parser.add_argument(
        "--batch-size", type=int, default=50,
        help="æ¯æ‰¹å¤„ç†çš„ç»„åˆæ•° (é»˜è®¤: 50ï¼Œå½±å“ checkpoint ç²’åº¦å’Œå†…å­˜å ç”¨)",
    )
    parser.add_argument(
        "--use-groups", action="store_true",
        help="å¯ç”¨åˆ†ç»„ç©·ä¸¾æ¨¡å¼ (æ¯ç»„åªé€‰ä¸€ä¸ªæ¨¡å‹)",
    )
    parser.add_argument(
        "--group-config", type=str, default="config/combo_groups.yaml",
        help="åˆ†ç»„é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: config/combo_groups.yaml)",
    )
    args = parser.parse_args()

    # åˆå§‹åŒ–
    print("=" * 60)
    print("Brute Force Ensemble - æš´åŠ›ç©·ä¸¾ç»„åˆå›æµ‹")
    print(f"å¯åŠ¨æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    init_qlib()

    # åŠ è½½é…ç½®
    train_records, model_config = load_config(args.record_file)
    anchor_date = train_records.get(
        "anchor_date", datetime.now().strftime("%Y-%m-%d")
    )
    top_k = model_config.get("TopK", 22)
    drop_n = model_config.get("DropN", 3)
    benchmark = model_config.get("benchmark", "SH000300")

    # è¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)

    # Stage 1: åŠ è½½é¢„æµ‹æ•°æ®
    norm_df, model_metrics = load_predictions(train_records)
    
    # åˆ’åˆ†æ•°æ®é›† (IS / OOS)
    is_norm_df, oos_norm_df = split_is_oos_by_args(norm_df, args)
    if is_norm_df.empty:
        print("é”™è¯¯: IS æœŸæ— æ•°æ®ï¼è¯·æ£€æŸ¥æ—¥æœŸå‚æ•°ã€‚")
        sys.exit(1)

    # Stage 2: ç›¸å…³æ€§åˆ†æ (åŸºäº IS)
    corr_matrix = correlation_analysis(is_norm_df, args.output_dir, anchor_date)

    if not args.analysis_only:
        # Stage 3: æš´åŠ›å›æµ‹ (åŸºäº IS)
        results_df = brute_force_backtest(
            norm_df=is_norm_df,
            top_k=top_k,
            drop_n=drop_n,
            benchmark=benchmark,
            freq=args.freq,
            min_combo_size=args.min_combo_size,
            max_combo_size=args.max_combo_size,
            output_dir=args.output_dir,
            anchor_date=anchor_date,
            resume=args.resume,
            n_jobs=args.n_jobs,
            use_groups=args.use_groups,
            group_config=args.group_config,
            batch_size=args.batch_size,
        )
    else:
        # ç›´æ¥è¯»å–å·²æœ‰ç»“æœ
        csv_path = os.path.join(
            args.output_dir, f"brute_force_results_{anchor_date}.csv"
        )
        if not os.path.exists(csv_path):
            import glob
            pattern = os.path.join(args.output_dir, "brute_force_results_*.csv")
            files = sorted(glob.glob(pattern))
            if files:
                csv_path = files[-1]
                print(f"ä½¿ç”¨æœ€æ–°ç»“æœæ–‡ä»¶: {csv_path}")
            else:
                print(f"é”™è¯¯: æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶ ({pattern})")
                sys.exit(1)
        results_df = pd.read_csv(csv_path)
        print(f"\nå·²åŠ è½½ç°æœ‰ç»“æœ: {csv_path} ({len(results_df)} æ¡)")

    # Stage 4: åˆ†æ
    if not args.skip_analysis and not results_df.empty:
        analyze_results(
            results_df=results_df,
            corr_matrix=corr_matrix,
            norm_df=is_norm_df,
            train_records=train_records,
            output_dir=args.output_dir,
            anchor_date=anchor_date,
            top_n=args.top_n,
        )
        
    # Stage 5: OOS éªŒè¯
    if getattr(args, "auto_test_top", 0) > 0 and not results_df.empty:
        if oos_norm_df.empty:
            print("\nâš ï¸ æ— æ³•è¿›è¡Œ OOS éªŒè¯ï¼šæ—  OOS æ•°æ®ï¼è¯·é…åˆä½¿ç”¨ --exclude-last-years æˆ–ç±»ä¼¼å‚æ•°ã€‚")
        else:
            print(f"\n{'='*60}")
            print(f"Stage 5: è‡ªåŠ¨ Out-Of-Sample (OOS) éªŒè¯ (Top {args.auto_test_top})")
            print(f"{'='*60}")
            
            top_combos = results_df.head(args.auto_test_top)["models"].tolist()
            
            # Init OOS Exchange
            from qlib.backtest.exchange import Exchange
            bt_start_oos = str(oos_norm_df.index.get_level_values(0).min().date())
            bt_end_oos = str(oos_norm_df.index.get_level_values(0).max().date())
            all_codes_oos = sorted(oos_norm_df.index.get_level_values(1).unique().tolist())
            
            exchange_kwargs = BACKTEST_CONFIG["exchange_kwargs"].copy()
            exchange_freq = exchange_kwargs.pop("freq", "day")
            
            trade_exchange_oos = Exchange(
                freq=exchange_freq,
                start_time=bt_start_oos,
                end_time=bt_end_oos,
                codes=all_codes_oos,
                **exchange_kwargs
            )
            
            oos_results = []
            for combo_str in tqdm(top_combos, desc="OOS Testing"):
                combo = combo_str.split(",")
                res = run_single_backtest(
                    combo, oos_norm_df, top_k, drop_n, benchmark, args.freq,
                    trade_exchange_oos, bt_start_oos, bt_end_oos
                )
                if res:
                    oos_results.append(res)
                    
            if oos_results:
                oos_df = pd.DataFrame(oos_results)
                oos_path = os.path.join(args.output_dir, f"oos_validation_{anchor_date}.csv")
                oos_df.to_csv(oos_path, index=False)
                print(f"OOS ç»“æœå·²ä¿å­˜: {oos_path}")
                
                print("\nOOS éªŒè¯ç»“æœ:")
                display_cols = ["models", "Ann_Ret", "Max_DD", "Ann_Excess", "Calmar"]
                fmt = {
                    "Ann_Ret": "{:.2%}".format,
                    "Max_DD": "{:.2%}".format,
                    "Ann_Excess": "{:.2%}".format,
                    "Calmar": "{:.2f}".format,
                }
                print(oos_df[display_cols].to_string(formatters=fmt))

    print(f"\n{'='*60}")
    print(f"å…¨éƒ¨å®Œæˆï¼ è€—æ—¶ç»“æŸäº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"{'='*60}")


if __name__ == "__main__":
    main()
