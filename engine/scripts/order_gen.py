#!/usr/bin/env python3
"""
Order Generation - åŸºäºèåˆ/å•æ¨¡å‹é¢„æµ‹ç”Ÿæˆä¹°å–è®¢å•

å·¥ä½œæµä½ç½®ï¼šè®­ç»ƒ â†’ ç©·ä¸¾ â†’ èåˆå›æµ‹ â†’ Post-Trade â†’ **è®¢å•ç”Ÿæˆï¼ˆæœ¬è„šæœ¬ï¼‰**

å‰ç½®æ¡ä»¶ï¼š
  - å·²è¿è¡Œé¢„æµ‹/èåˆè„šæœ¬ï¼Œoutput/predictions/ ä¸­æœ‰é¢„æµ‹ç»“æœ
  - å·²è¿è¡Œ post-trade è„šæœ¬ï¼Œweekly_config.json ä¸­æœ‰æœ€æ–°æŒä»“å’Œç°é‡‘

è¿è¡Œæ–¹å¼ï¼š
  # ä½¿ç”¨æœ€æ–°èåˆé¢„æµ‹
  python engine/scripts/order_gen.py

  # ä½¿ç”¨å•æ¨¡å‹é¢„æµ‹ï¼ˆä¸èåˆï¼‰
  python engine/scripts/order_gen.py --model gru

  # æŒ‡å®šé¢„æµ‹æ–‡ä»¶
  python engine/scripts/order_gen.py --prediction-file output/predictions/ensemble_2026-02-06.csv

  # ä»…é¢„è§ˆ
  python engine/scripts/order_gen.py --dry-run

å‚æ•°ï¼š
  --model            ä½¿ç”¨å•æ¨¡å‹é¢„æµ‹ï¼ˆä» output/predictions/{model}_{date}.csv åŠ è½½ï¼‰
  --prediction-file  ç›´æ¥æŒ‡å®šé¢„æµ‹æ–‡ä»¶è·¯å¾„
  --output-dir       è¾“å‡ºç›®å½• (é»˜è®¤ output)
  --dry-run          ä»…æ‰“å°è®¢å•è®¡åˆ’ï¼Œä¸å†™å…¥æ–‡ä»¶
  --verbose          æ˜¾ç¤ºè¯¦ç»†çš„æ’åå’Œä»·æ ¼ä¿¡æ¯
"""

import os
import sys
import json
import glob
import argparse
from datetime import datetime

import numpy as np
import pandas as pd

# ---------------------------------------------------------------------------
# è·¯å¾„è®¾ç½®
# ---------------------------------------------------------------------------
import env

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = env.ROOT_DIR
os.chdir(ROOT_DIR)

CONFIG_FILE = os.path.join(ROOT_DIR, "config", "weekly_config.json")
CASHFLOW_FILE = os.path.join(ROOT_DIR, "config", "cashflow.json")
PREDICTION_DIR = os.path.join(ROOT_DIR, "output", "predictions")
ENSEMBLE_CONFIG_FILE = os.path.join(ROOT_DIR, "config", "ensemble_config.json")


# ============================================================================
# Stage 0: åˆå§‹åŒ– & é…ç½®åŠ è½½
# ============================================================================
def init_qlib():
    """åˆå§‹åŒ– Qlib"""
    import qlib
    from qlib.constant import REG_CN
    provider_uri = "~/.qlib/qlib_data/cn_data"
    qlib.init(provider_uri=provider_uri, region=REG_CN)


def get_anchor_date():
    """è·å–é”šç‚¹æ—¥æœŸï¼ˆæœ€è¿‘çš„å‰ä¸€äº¤æ˜“æ—¥ï¼‰"""
    from qlib.data import D
    last_trade_date = D.calendar(future=False)[-1:][0]
    return last_trade_date.strftime('%Y-%m-%d')


def load_configs():
    """åŠ è½½ weekly_config.json å’Œ cashflow.json"""
    with open(CONFIG_FILE, 'r') as f:
        config = json.load(f)

    cashflow_config = {}
    if os.path.exists(CASHFLOW_FILE):
        with open(CASHFLOW_FILE, 'r') as f:
            cashflow_config = json.load(f)

    return config, cashflow_config


def get_cashflow_today(cashflow_config, anchor_date):
    """è·å–å½“æ—¥ cashflow é‡‘é¢ï¼ˆæ”¯æŒæ–°æ—§ä¸¤ç§æ ¼å¼ï¼‰"""
    # æ–°æ ¼å¼: {"cashflows": {"2026-02-03": 50000}}
    cashflows = cashflow_config.get('cashflows', {})
    if cashflows and anchor_date in cashflows:
        return float(cashflows[anchor_date])

    # æ—§æ ¼å¼: {"cash_flow_today": 50000}
    return float(cashflow_config.get('cash_flow_today', 0))


# ============================================================================
# Stage 1: åŠ è½½é¢„æµ‹æ•°æ®
# ============================================================================
def load_predictions(prediction_file=None, model_name=None, anchor_date=None):
    """
    åŠ è½½é¢„æµ‹æ•°æ®ã€‚

    ä¼˜å…ˆçº§: prediction_file > model_name > è‡ªåŠ¨æœç´¢ ensemble CSV

    Args:
        prediction_file: ç›´æ¥æŒ‡å®šçš„é¢„æµ‹æ–‡ä»¶è·¯å¾„
        model_name: å•æ¨¡å‹åç§°
        anchor_date: é”šç‚¹æ—¥æœŸ

    Returns:
        pred_df: DataFrame with 'score' column, index=(instrument,) or (instrument, datetime)
        source_desc: str, é¢„æµ‹æ¥æºæè¿°
    """
    if prediction_file:
        # ç›´æ¥æŒ‡å®šæ–‡ä»¶
        if not os.path.exists(prediction_file):
            raise FileNotFoundError(f"æŒ‡å®šçš„é¢„æµ‹æ–‡ä»¶ä¸å­˜åœ¨: {prediction_file}")
        pred_df = pd.read_csv(prediction_file, index_col=[0, 1], parse_dates=[1])
        return pred_df, f"æŒ‡å®šæ–‡ä»¶: {prediction_file}"

    if model_name:
        # æŒ‰æ¨¡å‹åæœç´¢
        pattern = os.path.join(PREDICTION_DIR, f"{model_name}_*.csv")
        files = sorted(glob.glob(pattern))
        if not files:
            raise FileNotFoundError(
                f"æœªæ‰¾åˆ°æ¨¡å‹ {model_name} çš„é¢„æµ‹æ–‡ä»¶ã€‚\n"
                f"æœç´¢è·¯å¾„: {pattern}\n"
                f"è¯·å…ˆè¿è¡Œè®­ç»ƒ/é¢„æµ‹è„šæœ¬ã€‚"
            )
        pred_file = files[-1]
        pred_df = pd.read_csv(pred_file, index_col=[0, 1], parse_dates=[1])
        return pred_df, f"å•æ¨¡å‹: {model_name} ({os.path.basename(pred_file)})"

    # è‡ªåŠ¨æœç´¢ ensemble é¢„æµ‹
    # ä¼˜å…ˆçº§: ensemble_YYYY-MM-DD.csv (default combo çš„å‘åå…¼å®¹å‰¯æœ¬)
    #       > ensemble_default_YYYY-MM-DD.csv (æ˜¾å¼ default combo)
    #       > ensemble_*.csv (ä»»æ„ combo)
    pred_file = None

    # 1) å‘åå…¼å®¹æ ¼å¼: ensemble_YYYY-MM-DD.csv (æ—  combo å)
    compat_pattern = os.path.join(PREDICTION_DIR, "ensemble_[0-9]*.csv")
    compat_files = sorted(glob.glob(compat_pattern))
    if compat_files:
        pred_file = compat_files[-1]

    # 2) è‹¥æ— ï¼Œå°è¯• ensemble_default_YYYY-MM-DD.csv
    if not pred_file:
        default_pattern = os.path.join(PREDICTION_DIR, "ensemble_default_*.csv")
        default_files = sorted(glob.glob(default_pattern))
        if default_files:
            pred_file = default_files[-1]

    # 3) è‹¥ä»æ— ï¼Œå›é€€åˆ°ä»»æ„ ensemble_*.csvï¼ˆæŒ‰æ—¥æœŸæ’åºï¼‰
    if not pred_file:
        pattern = os.path.join(PREDICTION_DIR, "ensemble_*.csv")
        files = sorted(glob.glob(pattern))
        if not files:
            raise FileNotFoundError(
                "æœªæ‰¾åˆ° ensemble é¢„æµ‹æ–‡ä»¶ã€‚\n"
                f"æœç´¢è·¯å¾„: {pattern}\n"
                "è¯·å…ˆè¿è¡Œ ensemble_fusion.pyï¼Œæˆ–ä½¿ç”¨ --model æŒ‡å®šå•æ¨¡å‹ã€‚"
            )
        pred_file = files[-1]
    pred_df = pd.read_csv(pred_file, index_col=[0, 1], parse_dates=[1])

    # å°è¯•åŠ è½½å¯¹åº”çš„ ensemble é…ç½®
    config_pattern = os.path.join(ROOT_DIR, "output", "ensemble", "ensemble_fusion_config_*.json")
    config_files = sorted(glob.glob(config_pattern))
    # ä¹Ÿæ£€æŸ¥æ—§æ ¼å¼ä½ç½®
    if not config_files:
        config_pattern = os.path.join(ROOT_DIR, "output", "ensemble_config_*.json")
        config_files = sorted(glob.glob(config_pattern))

    ensemble_info = ""
    if config_files:
        try:
            with open(config_files[-1], 'r') as f:
                ens_cfg = json.load(f)
            method = ens_cfg.get('weight_mode', ens_cfg.get('method', 'unknown'))
            models = ens_cfg.get('models_used', [])
            ensemble_info = f"\n  èåˆæ–¹å¼: {method}\n  æ¨¡å‹ç»„åˆ: {', '.join(models)}"
        except Exception:
            pass

    return pred_df, f"Ensemble èåˆ ({os.path.basename(pred_file)}){ensemble_info}"


# ============================================================================
# Stage 2: ä»·æ ¼æ•°æ®è·å–
# ============================================================================
def get_price_data(anchor_date, market):
    """
    è·å–å½“æ—¥å¤æƒä»·æ ¼å’Œæ¶¨è·Œåœä¼°ä»·ã€‚

    Args:
        anchor_date: é”šç‚¹æ—¥æœŸ
        market: å¸‚åœºåç§°

    Returns:
        price_df: DataFrame with columns [current_close, possible_max, possible_min]
    """
    from qlib.data import D
    from qlib.data.ops import Feature

    instruments = D.instruments(market=market)
    current_close = Feature("close") / Feature("factor")
    possible_max = Feature("close") / Feature("factor") * 1.1
    possible_min = Feature("close") / Feature("factor") * 0.9

    features_df = D.features(
        instruments=instruments,
        start_time=anchor_date,
        fields=[current_close, possible_max, possible_min]
    )

    features_df.rename(columns={
        'Div($close,$factor)': 'current_close',
        'Mul(Div($close,$factor),1.1)': 'possible_max',
        'Mul(Div($close,$factor),0.9)': 'possible_min'
    }, inplace=True)

    return features_df


# ============================================================================
# Stage 3: æ’åºä¸æŒä»“åˆ†æ
# ============================================================================
def analyze_positions(pred_df, price_df, current_holding, top_k, drop_n,
                      buy_suggestion_factor):
    """
    æŒ‰ score æ’åï¼Œç¡®å®šç»§ç»­æŒæœ‰/å–å‡º/ä¹°å…¥å€™é€‰ã€‚

    Args:
        pred_df: é¢„æµ‹æ•°æ®
        price_df: ä»·æ ¼æ•°æ®
        current_holding: å½“å‰æŒä»“åˆ—è¡¨
        top_k: ç›®æ ‡æŒä»“æ•°
        drop_n: æ¯æœŸå–å‡ºæ•°
        buy_suggestion_factor: ä¹°å…¥å€™é€‰å€æ•°

    Returns:
        hold_final: ç»§ç»­æŒæœ‰çš„ DataFrame
        sell_candidates: å–å‡ºå€™é€‰çš„ DataFrame
        buy_candidates: ä¹°å…¥å€™é€‰çš„ DataFrame
        merged_df: åˆå¹¶åçš„å®Œæ•´æ’å DataFrame
    """
    # å–é¢„æµ‹æ•°æ®æœ€æ–°ä¸€å¤©
    latest_date = pred_df.index.get_level_values('datetime').max()
    if len(pred_df.index.get_level_values('datetime').unique()) > 1:
        daily_pred = pred_df.xs(latest_date, level='datetime')
    else:
        daily_pred = pred_df

    # daily_pred å¯èƒ½æœ‰ datetime åœ¨ index level ä¹Ÿå¯èƒ½æ²¡æœ‰
    if 'instrument' in daily_pred.columns:
        pred_reset = daily_pred
    else:
        pred_reset = daily_pred.reset_index()

    price_reset = price_df.reset_index()

    # åˆå¹¶é¢„æµ‹ä¸ä»·æ ¼
    merged_df = pd.merge(
        pred_reset, price_reset,
        on='instrument', how='inner'
    )

    # æ’åº
    sorted_df = merged_df.sort_values(by='score', ascending=False).set_index('instrument')

    # å½“å‰æŒä»“ instrument åˆ—è¡¨
    current_holding_instruments = [h['instrument'] for h in current_holding]

    # Top K + buffer
    top_k_candidates = sorted_df.head(top_k + drop_n * buy_suggestion_factor)

    # ç»§ç»­æŒæœ‰ï¼šåœ¨ Top K buffer ä¸­çš„å½“å‰æŒä»“
    hold_candidates = top_k_candidates[
        top_k_candidates.index.isin(current_holding_instruments)
    ]

    # å½“å‰æŒä»“ä¸­éœ€è¦å–å‡ºçš„ï¼ˆä¸åœ¨ Top K buffer ä¸­çš„æŒä»“ï¼Œå–æ’åæœ€ä½çš„ drop_n ä¸ªï¼‰
    current_holding_in_df = sorted_df[sorted_df.index.isin(current_holding_instruments)]
    sell_candidates = current_holding_in_df[
        ~current_holding_in_df.index.isin(hold_candidates.index)
    ].tail(drop_n)

    # å®é™…æŒæœ‰ = å½“å‰æŒä»“ - å–å‡º
    hold_final = current_holding_in_df[
        ~current_holding_in_df.index.isin(sell_candidates.index)
    ]

    # ä¹°å…¥å€™é€‰ï¼šéœ€è¦ä¹°å…¥çš„æ•°é‡ = TopK - æŒæœ‰æ•°
    buy_count = top_k - len(hold_final)
    buy_candidates = top_k_candidates[
        ~top_k_candidates.index.isin(hold_final.index)
    ].head(max(0, buy_count * buy_suggestion_factor))

    return hold_final, sell_candidates, buy_candidates, sorted_df, buy_count


# ============================================================================
# Stage 4: å–å‡ºè®¢å•ç”Ÿæˆ
# ============================================================================
def generate_sell_orders(sell_candidates, current_holding, next_trade_date_string):
    """
    ç”Ÿæˆå–å‡ºè®¢å•ã€‚

    Args:
        sell_candidates: å–å‡ºå€™é€‰ DataFrame
        current_holding: å½“å‰æŒä»“åˆ—è¡¨
        next_trade_date_string: ä¸‹ä¸€äº¤æ˜“æ—¥å­—ç¬¦ä¸²

    Returns:
        sell_orders: list of dict
        sell_amount: float, é¢„ä¼°å–å‡ºæ€»é‡‘é¢
    """
    holdings_dict = {h['instrument']: float(h['value']) for h in current_holding}
    sell_orders = []
    sell_amount = 0

    for instrument, row in sell_candidates.iterrows():
        if instrument in holdings_dict:
            value = holdings_dict[instrument]
            amount = value * row['possible_min']
            sell_amount += amount
            sell_orders.append({
                'instrument': instrument,
                'datetime': next_trade_date_string,
                'value': int(value),
                'estimated_amount': round(amount, 2),
                'score': round(row['score'], 6),
                'current_close': round(row['current_close'], 2),
            })

    return sell_orders, sell_amount


# ============================================================================
# Stage 5: ä¹°å…¥è®¢å•ç”Ÿæˆ
# ============================================================================
def generate_buy_orders(buy_candidates, buy_count, available_cash,
                        next_trade_date_string):
    """
    ç”Ÿæˆä¹°å…¥è®¢å•ï¼ˆæ‰€æœ‰ NÃ—factor ä¸ªå¤‡é€‰ï¼‰ã€‚

    Args:
        buy_candidates: ä¹°å…¥å€™é€‰ DataFrameï¼ˆå·²æŒ‰ score é™åºï¼‰
        buy_count: å®é™…éœ€è¦ä¹°å…¥çš„æ•°é‡
        available_cash: å¯ç”¨ç°é‡‘
        next_trade_date_string: ä¸‹ä¸€äº¤æ˜“æ—¥å­—ç¬¦ä¸²

    Returns:
        buy_orders: list of dict
    """
    avg_cash = available_cash / buy_count if buy_count > 0 else 0

    buy_orders = []
    for instrument, row in buy_candidates.iterrows():
        value = int(np.floor(avg_cash / row['possible_max'] / 100) * 100)
        if value >= 100:
            amount = value * row['possible_max']
            buy_orders.append({
                'instrument': instrument,
                'datetime': next_trade_date_string,
                'value': value,
                'estimated_amount': round(amount, 2),
                'score': round(row['score'], 6),
                'current_close': round(row['current_close'], 2),
            })

    return buy_orders


# ============================================================================
# Stage 3.5: å¤šæ¨¡å‹åˆ¤æ–­è¡¨
# ============================================================================
def _load_pred_latest_day(pred_source, source_type, valid_instruments=None):
    """
    ç»Ÿä¸€åŠ è½½é¢„æµ‹æ•°æ®å¹¶è¿”å›æœ€æ–°ä¸€å¤©çš„ DataFrameï¼ˆæŒ‰ score é™åºï¼Œindex=instrumentï¼‰ã€‚

    æ”¯æŒ:
      - CSV æ–‡ä»¶ (score åˆ— æˆ– åˆ—åä¸º '0')
      - Qlib Recorder pkl DataFrame

    Args:
        pred_source: æ–‡ä»¶è·¯å¾„æˆ– DataFrame
        source_type: 'model', 'combo', 'model_pkl'
        valid_instruments: set, å¯é€‰, ä»…ä¿ç•™è¿™äº›æ ‡çš„
    """
    if source_type == 'model_pkl':
        df = pred_source.copy()
    else:
        df = pd.read_csv(pred_source)
        # ç»Ÿä¸€åˆ—å: å•æ¨¡å‹ CSV çš„é¢„æµ‹åˆ—å¯èƒ½å« '0'
        if '0' in df.columns and 'score' not in df.columns:
            df = df.rename(columns={'0': 'score'})
        # è®¾ç½® multi-index
        if 'instrument' in df.columns and 'datetime' in df.columns:
            df = df.set_index(['instrument', 'datetime'])

    # ç¡®ä¿æœ‰ score åˆ—
    if 'score' not in df.columns:
        num_cols = df.select_dtypes(include='number').columns.tolist()
        if num_cols:
            df = df.rename(columns={num_cols[0]: 'score'})
        else:
            return None

    # å–æœ€æ–°ä¸€å¤©
    if 'datetime' in df.index.names:
        latest_date = df.index.get_level_values('datetime').max()
        if len(df.index.get_level_values('datetime').unique()) > 1:
            daily_df = df.xs(latest_date, level='datetime')
        else:
            daily_df = df.droplevel('datetime') if 'datetime' in df.index.names else df
    elif 'datetime' in df.columns:
        latest_date = df['datetime'].max()
        daily_df = df[df['datetime'] == latest_date].set_index('instrument')
    else:
        daily_df = df

    # ç¡®ä¿ index æ˜¯ instrument
    if 'instrument' in daily_df.columns:
        daily_df = daily_df.set_index('instrument')

    # è¿‡æ»¤åˆ°æœ‰æ•ˆæ ‡çš„ï¼ˆä¸ analyze_positions çš„ price merge å¯¹é½ï¼‰
    if valid_instruments is not None:
        daily_df = daily_df[daily_df.index.isin(valid_instruments)]

    return daily_df.sort_values('score', ascending=False)


def generate_model_opinions(focus_instruments, current_holding_instruments,
                            top_k, drop_n, buy_suggestion_factor,
                            sorted_df, output_dir, next_trade_date_string,
                            dry_run=False):
    """
    åŠ è½½æ‰€æœ‰ combo å’Œå•ä¸€æ¨¡å‹çš„é¢„æµ‹ï¼Œå¯¹æ¯ä¸ªæ ‡çš„ç”Ÿæˆåˆ¤æ–­ã€‚

    åˆ¤æ–­é€»è¾‘ï¼ˆä¸ analyze_positions ä¸€è‡´ï¼‰ï¼š
      - æŒä»“åœ¨å€™é€‰æ± å†… â†’ HOLD
      - æŒä»“æ± å¤–, æœ€å·® DropN â†’ SELL
      - æŒä»“æ± å¤–, éæœ€å·® â†’ HOLD
      - éæŒä»“, æ’åé å‰ â†’ BUY / BUY*
      - éæŒä»“, æ’åé å â†’ --

    Args:
        focus_instruments: list, å…³æ³¨æ ‡çš„åˆ—è¡¨
        current_holding_instruments: list, å½“å‰æŒä»“ä»£ç åˆ—è¡¨
        top_k: TopK é˜ˆå€¼
        drop_n: DropN é˜ˆå€¼
        buy_suggestion_factor: ä¹°å…¥å€æ•°
        sorted_df: DataFrame, analyze_positions è¾“å‡ºçš„æ’åºæ•°æ®ï¼ˆå·²ä¸ä»·æ ¼åˆå¹¶ï¼‰
        output_dir: è¾“å‡ºç›®å½•
        next_trade_date_string: ä¸‹ä¸€äº¤æ˜“æ—¥
        dry_run: æ˜¯å¦ dry-run æ¨¡å¼

    Returns:
        opinions_df, combo_info
    """
    # æœ‰æ•ˆæ ‡çš„é›†åˆï¼ˆåªè€ƒè™‘æœ‰ä»·æ ¼æ•°æ®çš„ï¼‰
    valid_instruments = set(sorted_df.index.tolist())

    # åŠ è½½ ensemble é…ç½®
    combos = {}
    if os.path.exists(ENSEMBLE_CONFIG_FILE):
        with open(ENSEMBLE_CONFIG_FILE, 'r') as f:
            config = json.load(f)
        if 'combos' in config:
            combos = config['combos']
        elif 'models' in config:
            combos = {'legacy': {
                'models': config['models'],
                'default': True,
            }}

    # æ”¶é›†æ‰€æœ‰é¢„æµ‹æº: (label, source, source_type, details)
    sources = []
    combo_info = {}

    # 1) Combo é¢„æµ‹
    for combo_name, cfg in combos.items():
        combo_info[combo_name] = cfg.get('models', [])
        pattern = os.path.join(PREDICTION_DIR, f"ensemble_{combo_name}_*.csv")
        files = sorted(glob.glob(pattern))
        if files:
            sources.append((f"combo_{combo_name}", files[-1], 'combo', combo_name))
            continue
        if cfg.get('default', False):
            pattern2 = os.path.join(PREDICTION_DIR, "ensemble_*.csv")
            generic_files = []
            for f_path in sorted(glob.glob(pattern2)):
                basename = os.path.basename(f_path)
                rest = basename[len("ensemble_"):-len(".csv")]
                if len(rest) == 10 and rest[4] == '-' and rest[7] == '-':
                    generic_files.append(f_path)
            if generic_files:
                sources.append((f"combo_{combo_name}", generic_files[-1], 'combo', combo_name))

    # 2) å•ä¸€æ¨¡å‹é¢„æµ‹ (CSV ä¼˜å…ˆ, Qlib Recorder åå¤‡)
    all_single_models = set()
    for cfg in combos.values():
        all_single_models.update(cfg.get('models', []))
    for model_name in sorted(all_single_models):
        pattern = os.path.join(PREDICTION_DIR, f"{model_name}_*.csv")
        files = sorted(glob.glob(pattern))
        if files:
            sources.append((f"model_{model_name}", files[-1], 'model', model_name))
        else:
            try:
                train_records_file = os.path.join(ROOT_DIR, 'config', 'latest_train_records.json')
                if os.path.exists(train_records_file):
                    with open(train_records_file, 'r') as f:
                        train_records = json.load(f)
                    record_id = train_records.get('models', {}).get(model_name)
                    if record_id:
                        from qlib.workflow import R
                        experiment_name = train_records.get('experiment_name', 'weekly_train')
                        recorder = R.get_recorder(recorder_id=record_id,
                                                  experiment_name=experiment_name)
                        pred_pkl = recorder.load_object('pred.pkl')
                        if pred_pkl is not None and len(pred_pkl) > 0:
                            sources.append((f"model_{model_name}", pred_pkl, 'model_pkl', model_name))
            except Exception:
                pass

    if not sources:
        print("  æœªæ‰¾åˆ°é¢å¤–é¢„æµ‹æ–‡ä»¶ï¼Œè·³è¿‡å¤šæ¨¡å‹åˆ¤æ–­")
        return None, {}

    # åœ¨æ‰€æœ‰æ¥æºå‰æ’å…¥ order_basisï¼ˆä½¿ç”¨ sorted_dfï¼Œä¸å®é™…è®¢å•å®Œå…¨ä¸€è‡´ï¼‰
    sources.insert(0, ("order_basis", None, 'sorted_df', 'order_basis'))

    print(f"  é¢„æµ‹æº: {len(sources)} ä¸ª "
          f"(order_basis: 1, combo: {sum(1 for s in sources if s[2] == 'combo')}, "
          f"model: {sum(1 for s in sources if s[2] in ('model', 'model_pkl'))})")

    # å¯¹æ¯ä¸ªé¢„æµ‹æºï¼Œæ¨¡æ‹Ÿ analyze_positions çš„æ¢ä»“é€»è¾‘
    holding_set = set(current_holding_instruments)

    # é¢„åŠ è½½æ‰€æœ‰é¢„æµ‹æºï¼ˆè¿‡æ»¤åˆ°æœ‰æ•ˆæ ‡çš„é›†åˆï¼Œä¸ analyze_positions å¯¹é½ï¼‰
    pred_cache = {}  # label -> sorted DataFrame or None
    for label, pred_source, source_type, detail in sources:
        if source_type == 'sorted_df':
            # ç›´æ¥ä½¿ç”¨ analyze_positions çš„è¾“å‡ºï¼ˆå·²æ’åºã€å·²åˆå¹¶ä»·æ ¼ï¼‰
            pred_cache[label] = sorted_df[['score']].sort_values('score', ascending=False)
            continue
        try:
            pred_cache[label] = _load_pred_latest_day(
                pred_source, source_type, valid_instruments=valid_instruments
            )
        except Exception:
            pred_cache[label] = None

    # å¯¹æ¯ä¸ªé¢„æµ‹æºï¼Œæ¨¡æ‹Ÿå®Œæ•´çš„æ¢ä»“å†³ç­–ï¼ˆä¸ analyze_positions ä¸€è‡´ï¼‰
    source_decisions = {}  # label -> {instrument: action}
    for label, pred_source, source_type, detail in sources:
        sorted_preds = pred_cache.get(label)
        if sorted_preds is None:
            source_decisions[label] = {}
            continue

        decisions = {}
        all_instruments = sorted_preds.index.tolist()  # å·²æŒ‰ score é™åº

        # 1) ç¡®å®šå€™é€‰æ±  = top (TopK + DropN * factor)
        pool_size = top_k + drop_n * buy_suggestion_factor
        pool_instruments = set(all_instruments[:pool_size])

        # 2) æŒä»“ä¸­åœ¨æ± å†…çš„ â†’ æš‚å®š HOLD
        held_in_pool = [inst for inst in all_instruments if inst in holding_set and inst in pool_instruments]
        # æŒä»“ä¸­åœ¨æ± å¤–çš„ â†’ å–å‡ºå€™é€‰ï¼ˆå–æœ€å·® DropNï¼‰
        held_outside_pool = [inst for inst in all_instruments if inst in holding_set and inst not in pool_instruments]
        sell_set = set(held_outside_pool[-drop_n:]) if held_outside_pool else set()

        # 3) æŒä»“å†³ç­–ï¼šå–å‡º or æŒæœ‰
        held_in_ranking = [inst for inst in all_instruments if inst in holding_set]
        for inst in held_in_ranking:
            decisions[inst] = 'SELL' if inst in sell_set else 'HOLD'

        # 4) ä¹°å…¥å†³ç­–
        hold_final_set = set(held_in_ranking) - sell_set
        buy_count = max(0, top_k - len(hold_final_set))

        # éæŒä»“çš„æ± å†…æ ‡çš„ï¼ŒæŒ‰æ’åå– buy_count * factor ä¸ª
        non_held_in_pool = [inst for inst in all_instruments[:pool_size] if inst not in holding_set]
        buy_primary = set(non_held_in_pool[:buy_count])
        buy_backup = set(non_held_in_pool[buy_count:buy_count * buy_suggestion_factor])

        for inst in non_held_in_pool:
            if inst in buy_primary:
                decisions[inst] = 'BUY'
            elif inst in buy_backup:
                decisions[inst] = 'BUY*'
            else:
                decisions[inst] = '--'

        # æ± å¤–çš„éæŒä»“
        for inst in all_instruments[pool_size:]:
            if inst not in holding_set:
                decisions[inst] = '--'

        # é™„åŠ æ’åä¿¡æ¯
        ranks = {inst: idx + 1 for idx, inst in enumerate(all_instruments)}
        for inst in decisions:
            if inst in ranks and decisions[inst] != '-':
                decisions[inst] = f"{decisions[inst]} ({ranks[inst]})"

        source_decisions[label] = decisions

    # ç»„è£… opinions è¡¨
    opinion_rows = []
    for instrument in focus_instruments:
        row = {'instrument': instrument}
        for label, pred_source, source_type, detail in sources:
            decisions = source_decisions.get(label, {})
            row[label] = decisions.get(instrument, '-')
        opinion_rows.append(row)

    opinions_df = pd.DataFrame(opinion_rows)
    if not opinions_df.empty:
        opinions_df = opinions_df.set_index('instrument')

    # æ„é€  combo ä¿¡æ¯
    model_to_combos = {}
    for combo_name, models in combo_info.items():
        for m in models:
            model_to_combos.setdefault(m, []).append(combo_name)

    # ä¿å­˜
    csv_file = os.path.join(output_dir, f"model_opinions_{next_trade_date_string}.csv")
    json_file = os.path.join(output_dir, f"model_opinions_{next_trade_date_string}.json")

    json_data = {
        'trade_date': next_trade_date_string,
        'combo_composition': combo_info,
        'model_to_combos': model_to_combos,
        'thresholds': {
            'TopK': top_k, 'DropN': drop_n,
            'buy_suggestion_factor': buy_suggestion_factor,
        },
        'legend': {
            'BUY': 'éæŒä»“, æ’åé å‰çš„ä¹°å…¥å€™é€‰ (æ•°é‡ = å–å‡ºæ•°)',
            'BUY*': 'éæŒä»“, å¤‡é€‰ä¹°å…¥ (åº”å¯¹åœç‰Œç­‰æƒ…å†µ)',
            'HOLD': 'æŒä»“, ç»§ç»­æŒæœ‰',
            'SELL': 'æŒä»“, TopK ä¹‹å¤–çš„æœ€å·® DropN',
            '--': 'éæŒä»“, ä¸åœ¨ä¹°å…¥å€™é€‰èŒƒå›´',
            '-': 'æ— æ•°æ®',
            'è¯´æ˜': 'å†³ç­–åçš„æ‹¬å·å†…æ•°å­—è¡¨ç¤ºè¯¥æ¨¡å‹æˆ–ç»„åˆä¸‹çš„é¢„æµ‹æ’å',
        },
        'sources': [(label,
                     'sorted_df (ä¸è®¢å•ä¸€è‡´)' if f is None
                     else (os.path.basename(f) if isinstance(f, str) else f'pkl:{detail}'),
                     stype) for label, f, stype, detail in sources],
    }

    if dry_run:
        print(f"  [DRY-RUN] ä¸å†™å…¥: {csv_file}")
        print(f"  [DRY-RUN] ä¸å†™å…¥: {json_file}")
    else:
        os.makedirs(output_dir, exist_ok=True)
        opinions_df.to_csv(csv_file)
        with open(json_file, 'w') as f:
            json.dump(json_data, f, indent=4, ensure_ascii=False)
        print(f"  å¤šæ¨¡å‹åˆ¤æ–­è¡¨: {csv_file}")
        print(f"  æ¨¡å‹ä¿¡æ¯æ±‡æ€»: {json_file}")

    return opinions_df, combo_info


# ============================================================================
# Stage 6: è¾“å‡ºä¸æ±‡æ€»
# ============================================================================
def save_orders(sell_orders, buy_orders, next_trade_date_string, output_dir,
                source_label, dry_run=False):
    """
    ä¿å­˜è®¢å• CSV æ–‡ä»¶å’Œæ±‡æ€»è®¢å• JSONã€‚

    Args:
        sell_orders: å–å‡ºè®¢å•åˆ—è¡¨
        buy_orders: ä¹°å…¥è®¢å•åˆ—è¡¨
        next_trade_date_string: ä¸‹ä¸€äº¤æ˜“æ—¥
        output_dir: è¾“å‡ºç›®å½•
        source_label: é¢„æµ‹æ¥æºæ ‡ç­¾ï¼ˆç”¨äºæ–‡ä»¶å‘½åï¼‰
        dry_run: æ˜¯å¦ dry-run æ¨¡å¼

    Returns:
        sell_file, buy_file: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„ï¼ˆdry-run æ—¶è¿”å›ç›®æ ‡è·¯å¾„ä½†ä¸å®é™…å†™å…¥ï¼‰
    """
    sell_df = pd.DataFrame(sell_orders)
    buy_df = pd.DataFrame(buy_orders)

    sell_file = os.path.join(output_dir, f"sell_suggestion_{source_label}_{next_trade_date_string}.csv")
    buy_file = os.path.join(output_dir, f"buy_suggestion_{source_label}_{next_trade_date_string}.csv")

    if dry_run:
        print(f"\n[DRY-RUN] ä»¥ä¸‹æ–‡ä»¶ä¸ä¼šè¢«å†™å…¥:")
        print(f"  å–å‡ºè®¢å•: {sell_file}")
        print(f"  ä¹°å…¥è®¢å•: {buy_file}")
    else:
        os.makedirs(output_dir, exist_ok=True)
        if not sell_df.empty:
            sell_df.to_csv(sell_file, index=False)
        if not buy_df.empty:
            buy_df.to_csv(buy_file, index=False)
        print(f"\nğŸ“ è®¢å•æ–‡ä»¶å·²ä¿å­˜:")
        print(f"  å–å‡ºè®¢å•: {sell_file}")
        print(f"  ä¹°å…¥è®¢å•: {buy_file}")

    return sell_file, buy_file


# ============================================================================
# Main
# ============================================================================
def main():
    parser = argparse.ArgumentParser(
        description='Order Generation - åŸºäºèåˆ/å•æ¨¡å‹é¢„æµ‹ç”Ÿæˆä¹°å–è®¢å•',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ï¼š
  # ä½¿ç”¨æœ€æ–°èåˆé¢„æµ‹
  python engine/scripts/order_gen.py

  # ä½¿ç”¨å•æ¨¡å‹é¢„æµ‹ï¼ˆä¸èåˆï¼‰
  python engine/scripts/order_gen.py --model gru

  # æŒ‡å®šé¢„æµ‹æ–‡ä»¶
  python engine/scripts/order_gen.py --prediction-file output/predictions/ensemble_2026-02-06.csv

  # ä»…é¢„è§ˆ
  python engine/scripts/order_gen.py --dry-run
"""
    )
    parser.add_argument('--model', type=str,
                        help='ä½¿ç”¨å•æ¨¡å‹é¢„æµ‹ï¼ˆä» output/predictions/{model}_{date}.csv åŠ è½½ï¼‰')
    parser.add_argument('--prediction-file', type=str,
                        help='ç›´æ¥æŒ‡å®šé¢„æµ‹æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output-dir', type=str, default='output',
                        help='è¾“å‡ºç›®å½• (é»˜è®¤ output)')
    parser.add_argument('--dry-run', action='store_true',
                        help='ä»…æ‰“å°è®¢å•è®¡åˆ’ï¼Œä¸å†™å…¥æ–‡ä»¶')
    parser.add_argument('--verbose', action='store_true',
                        help='æ˜¾ç¤ºè¯¦ç»†çš„æ’åå’Œä»·æ ¼ä¿¡æ¯')

    args = parser.parse_args()

    # ---- Stage 0: åˆå§‹åŒ– ----
    print(f"\n{'#'*60}")
    print("# Order Generation â€” è®¢å•ç”Ÿæˆ")
    print(f"# {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'#'*60}")

    if args.dry_run:
        print("\nâš ï¸  DRY-RUN æ¨¡å¼: ä¸ä¼šå†™å…¥ä»»ä½•æ–‡ä»¶")

    init_qlib()
    anchor_date = get_anchor_date()
    config, cashflow_config = load_configs()

    # è¯»å–å‚æ•°
    top_k = config.get('TopK', 22)
    drop_n = config.get('DropN', 3)
    buy_suggestion_factor = config.get('buy_suggestion_factor', 3)
    market = config.get('market', 'csi300')
    current_cash = float(config.get('current_cash', 0))
    current_holding = config.get('current_holding', [])
    cash_flow_today = get_cashflow_today(cashflow_config, anchor_date)

    print(f"\n{'='*60}")
    print("Stage 0: é…ç½®åŠ è½½")
    print(f"{'='*60}")
    print(f"é”šç‚¹æ—¥æœŸ   : {anchor_date}")
    print(f"å¸‚åœº       : {market}")
    print(f"TopK       : {top_k}")
    print(f"DropN      : {drop_n}")
    print(f"ä¹°å…¥å€æ•°   : {buy_suggestion_factor}")
    print(f"å½“å‰ç°é‡‘   : {current_cash:,.2f}")
    print(f"å½“å‰æŒä»“   : {len(current_holding)} ä¸ª")
    if cash_flow_today != 0:
        print(f"å½“æ—¥å‡ºå…¥é‡‘ : {cash_flow_today:+,.2f}")

    # ---- Stage 1: åŠ è½½é¢„æµ‹ ----
    print(f"\n{'='*60}")
    print("Stage 1: åŠ è½½é¢„æµ‹æ•°æ®")
    print(f"{'='*60}")

    pred_df, source_desc = load_predictions(
        prediction_file=args.prediction_file,
        model_name=args.model,
        anchor_date=anchor_date
    )

    print(f"é¢„æµ‹æ¥æº   : {source_desc}")
    print(f"é¢„æµ‹æ•°æ®é‡ : {len(pred_df)} æ¡")

    latest_date = pred_df.index.get_level_values('datetime').max()
    n_instruments = pred_df.xs(latest_date, level='datetime').shape[0] if \
        len(pred_df.index.get_level_values('datetime').unique()) > 1 else len(pred_df)
    print(f"æœ€æ–°æ—¥æœŸ   : {latest_date}")
    print(f"å½“æ—¥æ ‡çš„æ•° : {n_instruments}")

    # ---- Stage 2: ä»·æ ¼æ•°æ® ----
    print(f"\n{'='*60}")
    print("Stage 2: è·å–ä»·æ ¼æ•°æ®")
    print(f"{'='*60}")

    price_df = get_price_data(anchor_date, market)
    print(f"ä»·æ ¼æ•°æ®   : {len(price_df)} æ¡")

    # ---- è·å–ä¸‹ä¸€äº¤æ˜“æ—¥ ----
    from qlib.data import D
    target_dates = D.calendar(start_time=anchor_date, future=True)[:2]
    if len(target_dates) >= 2:
        next_trade_date = target_dates[1]
    else:
        next_trade_date = target_dates[0]
    next_trade_date_string = next_trade_date.strftime('%Y-%m-%d')
    print(f"ä¸‹ä¸€äº¤æ˜“æ—¥ : {next_trade_date_string}")

    # ---- Stage 3: æŒä»“åˆ†æ ----
    print(f"\n{'='*60}")
    print("Stage 3: æ’åºä¸æŒä»“åˆ†æ")
    print(f"{'='*60}")

    hold_final, sell_candidates, buy_candidates, sorted_df, buy_count = analyze_positions(
        pred_df, price_df, current_holding,
        top_k, drop_n, buy_suggestion_factor
    )

    print(f"ç»§ç»­æŒæœ‰   : {len(hold_final)} ä¸ª")
    print(f"è®¡åˆ’å–å‡º   : {len(sell_candidates)} ä¸ª")
    print(f"éœ€è¦ä¹°å…¥   : {buy_count} ä¸ª")
    print(f"ä¹°å…¥å€™é€‰   : {len(buy_candidates)} ä¸ª")

    if args.verbose:
        print(f"\n--- ç»§ç»­æŒæœ‰ ---")
        if len(hold_final) > 0:
            print(hold_final[['score', 'current_close']].to_string())

        print(f"\n--- å–å‡ºå€™é€‰ ---")
        if len(sell_candidates) > 0:
            print(sell_candidates[['score', 'current_close']].to_string())

        print(f"\n--- ä¹°å…¥å€™é€‰ ---")
        if len(buy_candidates) > 0:
            print(buy_candidates[['score', 'current_close']].to_string())

    # ---- Stage 3.5: å¤šæ¨¡å‹åˆ¤æ–­è¡¨ ----
    print(f"\n{'='*60}")
    print("Stage 3.5: å¤šæ¨¡å‹åˆ¤æ–­è¡¨")
    print(f"{'='*60}")

    # æ”¶é›†å…³æ³¨æ ‡çš„ï¼ˆæŒä»“ + ä¹°å…¥å€™é€‰ + å–å‡ºå€™é€‰ï¼‰
    focus_instruments = []
    for df in [hold_final, sell_candidates, buy_candidates]:
        if len(df) > 0:
            idx = df.index.get_level_values('instrument') if 'instrument' in df.index.names else df.index
            focus_instruments.extend(idx.tolist())
    focus_instruments = list(dict.fromkeys(focus_instruments))  # å»é‡ä¿åº

    # å½“å‰æŒä»“ä»£ç åˆ—è¡¨
    current_holding_instruments = [h['instrument'] for h in current_holding]

    opinions_df, combo_info = generate_model_opinions(
        focus_instruments, current_holding_instruments,
        top_k, drop_n, buy_suggestion_factor,
        sorted_df, args.output_dir, next_trade_date_string, dry_run=args.dry_run
    )

    if opinions_df is not None and not opinions_df.empty and args.verbose:
        print(f"\n--- å¤šæ¨¡å‹åˆ¤æ–­ï¼ˆå…³æ³¨æ ‡çš„ï¼‰ ---")
        print(opinions_df.to_string())
        if combo_info:
            print(f"\n--- Combo ç»„æˆ ---")
            for name, models in combo_info.items():
                print(f"  {name}: {', '.join(models)}")

    # ---- Stage 4: å–å‡ºè®¢å• ----
    print(f"\n{'='*60}")
    print("Stage 4: ç”Ÿæˆå–å‡ºè®¢å•")
    print(f"{'='*60}")

    sell_orders, sell_amount = generate_sell_orders(
        sell_candidates, current_holding, next_trade_date_string
    )

    if sell_orders:
        sell_df = pd.DataFrame(sell_orders)
        print(f"\nå–å‡ºè®¢å• ({len(sell_orders)} ç¬”ï¼Œé¢„ä¼°å›æ”¶ {sell_amount:,.2f}):")
        print(sell_df.to_string(index=False))
    else:
        print("æ— å–å‡ºè®¢å•")

    # ---- Stage 5: ä¹°å…¥è®¢å• ----
    print(f"\n{'='*60}")
    print("Stage 5: ç”Ÿæˆä¹°å…¥è®¢å•")
    print(f"{'='*60}")

    available_cash = current_cash + sell_amount + cash_flow_today
    print(f"å¯ç”¨ç°é‡‘   : {current_cash:,.2f} (ä½™é¢)")
    if sell_amount > 0:
        print(f"           + {sell_amount:,.2f} (é¢„ä¼°å–å‡ºå›æ”¶)")
    if cash_flow_today != 0:
        print(f"           + {cash_flow_today:+,.2f} (å‡ºå…¥é‡‘)")
    print(f"           = {available_cash:,.2f} (æ€»å¯ç”¨)")
    if buy_count > 0:
        print(f"æ¯è‚¡é¢„ç®—   : {available_cash / buy_count:,.2f}")

    buy_orders = generate_buy_orders(
        buy_candidates, buy_count, available_cash, next_trade_date_string
    )

    if buy_orders:
        buy_df = pd.DataFrame(buy_orders)
        amounts = sorted([o['estimated_amount'] for o in buy_orders])
        # é¢„ä¼°åŒºé—´ï¼šå– top buy_count ä¸ªæœ€å°/æœ€å¤§é‡‘é¢
        min_n = amounts[:buy_count]
        max_n = amounts[-buy_count:] if len(amounts) >= buy_count else amounts
        min_total = sum(min_n)
        max_total = sum(max_n)
        print(f"\nä¹°å…¥å¤‡é€‰ ({len(buy_orders)} ç¬”, å®é™…ä¹°å…¥ {buy_count} ä¸ª):")
        print(buy_df.to_string(index=False))
        if min_total == max_total:
            print(f"\nğŸ’° é¢„ä¼°æ”¯å‡º : {min_total:,.2f}")
        else:
            print(f"\nğŸ’° é¢„ä¼°æ”¯å‡ºåŒºé—´ : {min_total:,.2f} ~ {max_total:,.2f}")
    else:
        print("æ— ä¹°å…¥è®¢å•")

    # ---- Stage 6: ä¿å­˜ ----
    print(f"\n{'='*60}")
    print("Stage 6: ä¿å­˜è®¢å•")
    print(f"{'='*60}")

    # ç¡®å®šæ–‡ä»¶å‘½åæ ‡ç­¾
    if args.model:
        source_label = args.model
    elif args.prediction_file:
        source_label = "custom"
    else:
        source_label = "ensemble"

    sell_file, buy_file = save_orders(
        sell_orders, buy_orders, next_trade_date_string,
        args.output_dir, source_label, dry_run=args.dry_run
    )

    # ---- å®Œæˆ ----
    print(f"\n{'#'*60}")
    print("# âœ… è®¢å•ç”Ÿæˆå®Œæˆ!")
    print(f"{'#'*60}")
    print(f"ğŸ“… äº¤æ˜“æ—¥   : {next_trade_date_string}")
    print(f"ğŸ“Š é¢„æµ‹æ¥æº : {source_desc.split(chr(10))[0]}")
    print(f"ğŸ“Œ ç»§ç»­æŒæœ‰ : {len(hold_final)}")
    print(f"ğŸ“¤ å–å‡º     : {len(sell_orders)}")
    print(f"ğŸ“¥ ä¹°å…¥     : {len(buy_orders)}")
    if buy_orders:
        total_buy = sum(o['estimated_amount'] for o in buy_orders)
        print(f"ğŸ’° é¢„ä¼°æ”¯å‡º : {total_buy:,.2f}")
    if sell_orders:
        print(f"ğŸ’° é¢„ä¼°å›æ”¶ : {sell_amount:,.2f}")


if __name__ == "__main__":
    main()
