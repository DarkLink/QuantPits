#!/usr/bin/env python
"""
å¢é‡è®­ç»ƒè„šæœ¬ (Incremental Training)
é€‰æ‹©æ€§è®­ç»ƒä¸ªåˆ«æ¨¡å‹ï¼Œä»¥ merge æ–¹å¼æ›´æ–°è®­ç»ƒè®°å½•ï¼Œä¸å½±å“å…¶ä»–æ¨¡å‹ã€‚

æ ¸å¿ƒè¯­ä¹‰ï¼š
- åŒåæ¨¡å‹ â†’ è¦†ç›– recorder ID å’Œæ€§èƒ½æ•°æ®
- æ–°å¢æ¨¡å‹ â†’ è¿½åŠ åˆ°è®°å½•
- æœªè®­ç»ƒæ¨¡å‹ â†’ ä¿ç•™åŸæœ‰è®°å½•ä¸å˜

è¿è¡Œæ–¹å¼ï¼šcd QuantPits && python quantpits/scripts/incremental_train.py [options]

ç¤ºä¾‹ï¼š
  # æŒ‡å®šæ¨¡å‹è®­ç»ƒ
  python quantpits/scripts/incremental_train.py --models gru,mlp

  # æŒ‰ç®—æ³•ç­›é€‰
  python quantpits/scripts/incremental_train.py --algorithm lstm

  # æŒ‰æ•°æ®é›†ç­›é€‰
  python quantpits/scripts/incremental_train.py --dataset Alpha360

  # æŒ‰æ ‡ç­¾ç­›é€‰
  python quantpits/scripts/incremental_train.py --tag tree

  # è®­ç»ƒæ‰€æœ‰ enabled æ¨¡å‹ï¼ˆç­‰åŒå…¨é‡ä½†ä»¥ merge æ–¹å¼ä¿å­˜ï¼‰
  python quantpits/scripts/incremental_train.py --all-enabled

  # ä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­
  python quantpits/scripts/incremental_train.py --models gru,mlp,alstm_Alpha158 --resume

  # è·³è¿‡æŸäº›æ¨¡å‹
  python quantpits/scripts/incremental_train.py --all-enabled --skip catboost_Alpha158

  # Dry-runï¼ˆä»…æ‰“å°å¾…è®­ç»ƒæ¨¡å‹ï¼Œä¸å®é™…è®­ç»ƒï¼‰
  python quantpits/scripts/incremental_train.py --models gru,mlp --dry-run
"""

import os
import sys
import json
import argparse
from datetime import datetime

# è®¾ç½®å·¥ä½œç›®å½•
import env

SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
ROOT_DIR = env.ROOT_DIR
sys.path.append(SCRIPT_DIR)
os.chdir(ROOT_DIR)

# å»¶è¿Ÿå¯¼å…¥ qlibï¼ˆåœ¨è§£æå‚æ•°ä¹‹åï¼‰
def init_qlib():
    """åˆå§‹åŒ– Qlib ç¯å¢ƒ"""
    import qlib
    from qlib.constant import REG_CN
    provider_uri = "~/.qlib/qlib_data/cn_data"
    qlib.init(provider_uri=provider_uri, region=REG_CN)


def parse_args():
    parser = argparse.ArgumentParser(
        description='å¢é‡è®­ç»ƒï¼šé€‰æ‹©æ€§è®­ç»ƒä¸ªåˆ«æ¨¡å‹ï¼Œä»¥ merge æ–¹å¼æ›´æ–°è®°å½•',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s --models gru,mlp                    # è®­ç»ƒæŒ‡å®šæ¨¡å‹
  %(prog)s --algorithm lstm                     # è®­ç»ƒæ‰€æœ‰ LSTM ç³»åˆ—
  %(prog)s --dataset Alpha360                   # è®­ç»ƒæ‰€æœ‰ Alpha360 æ¨¡å‹
  %(prog)s --tag tree                           # è®­ç»ƒæ‰€æœ‰ tree æ ‡ç­¾æ¨¡å‹
  %(prog)s --all-enabled                        # è®­ç»ƒæ‰€æœ‰ enabled æ¨¡å‹
  %(prog)s --models gru,mlp --resume            # ä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­
  %(prog)s --all-enabled --skip catboost_Alpha158  # è·³è¿‡æŒ‡å®šæ¨¡å‹
  %(prog)s --models gru --dry-run               # ä»…æ‰“å°è®¡åˆ’ï¼Œä¸è®­ç»ƒ
  %(prog)s --list                               # åˆ—å‡ºæ‰€æœ‰æ³¨å†Œæ¨¡å‹
  %(prog)s --list --algorithm gru               # åˆ—å‡ºæ‰€æœ‰ GRU æ¨¡å‹
        """
    )
    
    # æ¨¡å‹é€‰æ‹©ï¼ˆäº’æ–¥ç»„ï¼šè‡³å°‘æŒ‡å®šä¸€ç§é€‰æ‹©æ–¹å¼ï¼‰
    select = parser.add_argument_group('æ¨¡å‹é€‰æ‹©')
    select.add_argument('--models', type=str,
                        help='æŒ‡å®šæ¨¡å‹åï¼Œé€—å·åˆ†éš” (å¦‚: gru,mlp,alstm_Alpha158)')
    select.add_argument('--algorithm', type=str,
                        help='æŒ‰ç®—æ³•ç­›é€‰ (å¦‚: lstm, gru, lightgbm)')
    select.add_argument('--dataset', type=str,
                        help='æŒ‰æ•°æ®é›†ç­›é€‰ (å¦‚: Alpha158, Alpha360)')
    select.add_argument('--market', type=str,
                        help='æŒ‰å¸‚åœºç­›é€‰ (å¦‚: csi300)')
    select.add_argument('--tag', type=str,
                        help='æŒ‰æ ‡ç­¾ç­›é€‰ (å¦‚: ts, tree, attention)')
    select.add_argument('--all-enabled', action='store_true',
                        help='è®­ç»ƒæ‰€æœ‰ enabled=true çš„æ¨¡å‹')
    
    # æ’é™¤ / è·³è¿‡
    skip_group = parser.add_argument_group('æ’é™¤ä¸è·³è¿‡')
    skip_group.add_argument('--skip', type=str,
                            help='è·³è¿‡æŒ‡å®šæ¨¡å‹ï¼Œé€—å·åˆ†éš”')
    skip_group.add_argument('--resume', action='store_true',
                            help='ä»ä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­ï¼ˆè·³è¿‡å·²å®Œæˆçš„æ¨¡å‹ï¼‰')
    
    # è¿è¡Œæ§åˆ¶
    ctrl = parser.add_argument_group('è¿è¡Œæ§åˆ¶')
    ctrl.add_argument('--dry-run', action='store_true',
                      help='ä»…æ‰“å°å¾…è®­ç»ƒæ¨¡å‹åˆ—è¡¨ï¼Œä¸å®é™…è®­ç»ƒ')
    ctrl.add_argument('--experiment-name', type=str, default=None,
                      help='MLflow å®éªŒåç§° (é»˜è®¤: Prod_Train_{FREQ})')
    
    # ä¿¡æ¯æŸ¥çœ‹
    info = parser.add_argument_group('ä¿¡æ¯æŸ¥çœ‹')
    info.add_argument('--list', action='store_true',
                      help='åˆ—å‡ºæ¨¡å‹æ³¨å†Œè¡¨ï¼ˆå¯ç»“åˆç­›é€‰æ¡ä»¶ï¼‰')
    info.add_argument('--show-state', action='store_true',
                      help='æ˜¾ç¤ºä¸Šæ¬¡è¿è¡ŒçŠ¶æ€')
    info.add_argument('--clear-state', action='store_true',
                      help='æ¸…é™¤è¿è¡ŒçŠ¶æ€æ–‡ä»¶')
    
    return parser.parse_args()


def resolve_target_models(args):
    """
    æ ¹æ® CLI å‚æ•°è§£æç›®æ ‡æ¨¡å‹åˆ—è¡¨
    
    Returns:
        dict: {model_name: model_info}
    """
    from train_utils import (
        load_model_registry,
        get_enabled_models,
        get_models_by_filter,
        get_models_by_names,
    )
    
    registry = load_model_registry()
    
    if args.models:
        # æŒ‰åç§°æŒ‡å®š
        model_names = [m.strip() for m in args.models.split(',')]
        targets = get_models_by_names(model_names, registry)
    elif args.all_enabled:
        # æ‰€æœ‰ enabled æ¨¡å‹
        targets = get_enabled_models(registry)
    elif args.algorithm or args.dataset or args.market or args.tag:
        # æŒ‰æ¡ä»¶ç­›é€‰
        targets = get_models_by_filter(
            registry,
            algorithm=args.algorithm,
            dataset=args.dataset,
            market=args.market,
            tag=args.tag
        )
    else:
        return None  # æ²¡æœ‰æŒ‡å®šä»»ä½•é€‰æ‹©æ¡ä»¶
    
    # åº”ç”¨ --skip
    if args.skip:
        skip_names = [m.strip() for m in args.skip.split(',')]
        targets = {k: v for k, v in targets.items() if k not in skip_names}
        if skip_names:
            print(f"â­ï¸  è·³è¿‡æ¨¡å‹: {', '.join(skip_names)}")
    
    return targets


def run_incremental_train(args):
    """æ‰§è¡Œå¢é‡è®­ç»ƒ"""
    from train_utils import (
        calculate_dates,
        train_single_model,
        merge_train_records,
        merge_performance_file,
        save_run_state,
        load_run_state,
        clear_run_state,
        print_model_table,
        backup_file_with_date,
        RECORD_OUTPUT_FILE,
    )
    
    # è§£æç›®æ ‡æ¨¡å‹
    targets = resolve_target_models(args)
    if targets is None:
        print("âŒ é”™è¯¯: è¯·æŒ‡å®šè‡³å°‘ä¸€ç§æ¨¡å‹é€‰æ‹©æ–¹å¼")
        print("   ä½¿ç”¨ --models, --algorithm, --dataset, --tag, æˆ– --all-enabled")
        print("   ä½¿ç”¨ --help æŸ¥çœ‹å®Œæ•´å¸®åŠ©")
        return
    
    if not targets:
        print("âš ï¸  æ²¡æœ‰åŒ¹é…çš„æ¨¡å‹")
        return
    
    # æ‰“å°å¾…è®­ç»ƒæ¨¡å‹
    print_model_table(targets, title="å¾…è®­ç»ƒæ¨¡å‹")
    
    # å¤„ç† resume æ¨¡å¼
    completed_models = set()
    if args.resume:
        state = load_run_state()
        if state and state.get('completed'):
            completed_models = set(state['completed'])
            # è¿‡æ»¤å·²å®Œæˆçš„æ¨¡å‹
            remaining = {k: v for k, v in targets.items() if k not in completed_models}
            if completed_models:
                skipped = [m for m in targets if m in completed_models]
                print(f"â© Resume æ¨¡å¼: è·³è¿‡å·²å®Œæˆçš„ {len(skipped)} ä¸ªæ¨¡å‹: {', '.join(skipped)}")
            targets = remaining
            
            if not targets:
                print("âœ… æ‰€æœ‰ç›®æ ‡æ¨¡å‹å·²åœ¨ä¸Šæ¬¡è¿è¡Œä¸­å®Œæˆ")
                return
            
            print_model_table(targets, title="å‰©ä½™å¾…è®­ç»ƒæ¨¡å‹")
        else:
            print("â„¹ï¸  æ²¡æœ‰æ‰¾åˆ°ä¸Šæ¬¡è¿è¡ŒçŠ¶æ€ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒ")
    
    # Dry-run æ¨¡å¼
    if args.dry_run:
        print("ğŸ” Dry-run æ¨¡å¼: ä»¥ä¸Šæ¨¡å‹å°†è¢«è®­ç»ƒï¼Œä½†æœ¬æ¬¡ä¸ä¼šå®é™…æ‰§è¡Œ")
        print("   å»æ‰ --dry-run å‚æ•°ä»¥å®é™…è¿è¡Œè®­ç»ƒ")
        return
    
    # ===== å¼€å§‹è®­ç»ƒ =====
    print("\n" + "="*60)
    print("ğŸš€ å¼€å§‹å¢é‡è®­ç»ƒ")
    print("="*60)
    
    # åˆå§‹åŒ– Qlib
    init_qlib()
    
    # è®¡ç®—æ—¥æœŸ
    params = calculate_dates()
    freq = params.get('freq', 'week').upper()
    
    experiment_name = args.experiment_name or f"Prod_Train_{freq}"
    
    # åˆå§‹åŒ–è¿è¡ŒçŠ¶æ€
    all_target_names = list(completed_models | set(targets.keys()))
    run_state = {
        'started_at': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'mode': 'incremental',
        'experiment_name': experiment_name,
        'anchor_date': params['anchor_date'],
        'target_models': all_target_names,
        'completed': list(completed_models),
        'failed': {},
        'skipped': []
    }
    save_run_state(run_state)
    
    # è®­ç»ƒç»“æœæ”¶é›†
    new_records = {
        "experiment_name": experiment_name,
        "anchor_date": params['anchor_date'],
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "models": {}
    }
    new_performances = {}
    
    total = len(targets)
    for idx, (model_name, model_info) in enumerate(targets.items(), 1):
        print(f"\n{'â”€'*60}")
        print(f"  [{idx}/{total}] {model_name}")
        print(f"{'â”€'*60}")
        
        yaml_file = model_info['yaml_file']
        
        result = train_single_model(model_name, yaml_file, params, experiment_name)
        
        if result['success']:
            new_records['models'][model_name] = result['record_id']
            if result['performance']:
                new_performances[model_name] = result['performance']
            
            # æ›´æ–°è¿è¡ŒçŠ¶æ€
            run_state['completed'].append(model_name)
        else:
            run_state['failed'][model_name] = result.get('error', 'Unknown error')
            print(f"âŒ æ¨¡å‹ {model_name} è®­ç»ƒå¤±è´¥: {result.get('error', 'Unknown')}")
        
        # å®æ—¶ä¿å­˜è¿è¡ŒçŠ¶æ€ï¼ˆé˜²æ­¢ä¸­æ–­ä¸¢å¤±è¿›åº¦ï¼‰
        save_run_state(run_state)
    
    # ===== åˆå¹¶è®°å½• =====
    if new_records['models']:
        print("\n" + "="*60)
        print("ğŸ“¦ åˆå¹¶è®­ç»ƒè®°å½•")
        print("="*60)
        
        # åˆå¹¶ latest_train_records.json
        merged = merge_train_records(new_records)
        
        # åˆå¹¶æ€§èƒ½æ–‡ä»¶
        if new_performances:
            merge_performance_file(new_performances, params['anchor_date'])
    
    # ===== è®­ç»ƒæ€»ç»“ =====
    print(f"\n{'='*60}")
    print("ğŸ“Š å¢é‡è®­ç»ƒå®Œæˆ")
    print("="*60)
    
    succeeded = run_state['completed']
    # åªæ˜¾ç¤ºæœ¬æ¬¡è®­ç»ƒçš„ï¼ˆæ’é™¤ resume å¸¦æ¥çš„å†å²å®Œæˆï¼‰
    this_run_completed = [m for m in succeeded if m in targets]
    failed = run_state['failed']
    
    print(f"  âœ… æˆåŠŸ: {len(this_run_completed)} ä¸ªæ¨¡å‹")
    for name in this_run_completed:
        perf = new_performances.get(name, {})
        ic = perf.get('IC_Mean', 'N/A')
        icir = perf.get('ICIR', 'N/A')
        ic_str = f"{ic:.4f}" if isinstance(ic, float) else ic
        icir_str = f"{icir:.4f}" if isinstance(icir, float) else icir
        print(f"    {name}: IC={ic_str}, ICIR={icir_str}")
    
    if failed:
        print(f"  âŒ å¤±è´¥: {len(failed)} ä¸ªæ¨¡å‹")
        for name, err in failed.items():
            print(f"    {name}: {err[:80]}")
        print(f"\n  ğŸ’¡ æç¤º: ä½¿ç”¨ --resume å‚æ•°å¯è·³è¿‡å·²æˆåŠŸçš„æ¨¡å‹ï¼Œé‡æ–°è®­ç»ƒå¤±è´¥çš„æ¨¡å‹")
    
    print(f"{'='*60}\n")
    
    # è®­ç»ƒå…¨éƒ¨æˆåŠŸæ—¶æ¸…é™¤è¿è¡ŒçŠ¶æ€
    if not failed:
        clear_run_state()


def show_list(args):
    """åˆ—å‡ºæ¨¡å‹æ³¨å†Œè¡¨"""
    from train_utils import (
        load_model_registry,
        get_models_by_filter,
        print_model_table,
    )
    
    registry = load_model_registry()
    
    # åº”ç”¨ç­›é€‰æ¡ä»¶
    if args.algorithm or args.dataset or args.market or args.tag:
        models = get_models_by_filter(
            registry,
            algorithm=args.algorithm,
            dataset=args.dataset,
            market=args.market,
            tag=args.tag
        )
        title = "ç­›é€‰ç»“æœ"
    else:
        models = registry
        title = "å…¨éƒ¨æ³¨å†Œæ¨¡å‹"
    
    print_model_table(models, title=title)
    
    # æ‰“å°å¯ç”¨/ç¦ç”¨ç»Ÿè®¡
    enabled_count = sum(1 for m in models.values() if m.get('enabled', False))
    disabled_count = len(models) - enabled_count
    print(f"  å¯ç”¨: {enabled_count}  |  ç¦ç”¨: {disabled_count}")
    
    # æŒ‰æ•°æ®é›†åˆ†ç»„ç»Ÿè®¡
    datasets = {}
    for name, info in models.items():
        ds = info.get('dataset', 'unknown')
        datasets.setdefault(ds, []).append(name)
    
    print(f"\n  æŒ‰æ•°æ®é›†åˆ†å¸ƒ:")
    for ds, names in sorted(datasets.items()):
        print(f"    {ds}: {len(names)} ({', '.join(names)})")


def show_state():
    """æ˜¾ç¤ºè¿è¡ŒçŠ¶æ€"""
    from train_utils import load_run_state
    
    state = load_run_state()
    if state is None:
        print("â„¹ï¸  æ²¡æœ‰æ‰¾åˆ°è¿è¡ŒçŠ¶æ€æ–‡ä»¶")
        return
    
    print("\nğŸ“‹ ä¸Šæ¬¡è¿è¡ŒçŠ¶æ€:")
    print(f"  å¼€å§‹æ—¶é—´: {state.get('started_at', 'N/A')}")
    print(f"  è¿è¡Œæ¨¡å¼: {state.get('mode', 'N/A')}")
    print(f"  å®éªŒåç§°: {state.get('experiment_name', 'N/A')}")
    print(f"  é”šç‚¹æ—¥æœŸ: {state.get('anchor_date', 'N/A')}")
    
    completed = state.get('completed', [])
    failed = state.get('failed', {})
    targets = state.get('target_models', [])
    remaining = [m for m in targets if m not in completed and m not in failed]
    
    print(f"\n  ç›®æ ‡æ¨¡å‹: {len(targets)} ä¸ª")
    if completed:
        print(f"  âœ… å·²å®Œæˆ: {len(completed)} - {', '.join(completed)}")
    if failed:
        print(f"  âŒ å¤±è´¥: {len(failed)}")
        for name, err in failed.items():
            print(f"      {name}: {err[:80]}")
    if remaining:
        print(f"  â³ æœªæ‰§è¡Œ: {len(remaining)} - {', '.join(remaining)}")


def main():
    args = parse_args()
    
    # ä¿¡æ¯æŸ¥çœ‹ç±»å‘½ä»¤ï¼ˆä¸éœ€è¦ Qlib åˆå§‹åŒ–ï¼‰
    if args.list:
        show_list(args)
        return
    
    if args.show_state:
        show_state()
        return
    
    if args.clear_state:
        from train_utils import clear_run_state
        clear_run_state()
        return
    
    # æ£€æŸ¥æ˜¯å¦æŒ‡å®šäº†æ¨¡å‹
    has_selection = any([
        args.models, args.algorithm, args.dataset,
        args.market, args.tag, args.all_enabled
    ])
    
    if not has_selection:
        print("âŒ è¯·æŒ‡å®šè¦è®­ç»ƒçš„æ¨¡å‹")
        print("   ä½¿ç”¨ --help æŸ¥çœ‹å®Œæ•´å¸®åŠ©")
        print("   ä½¿ç”¨ --list æŸ¥çœ‹æ‰€æœ‰å¯ç”¨æ¨¡å‹")
        return
    
    run_incremental_train(args)


if __name__ == "__main__":
    main()
